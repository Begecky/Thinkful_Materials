{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predicting the Success of Cyber-Related Terrorist Attacks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This dataset is from Global Terrorism Database curated by the University of Maryland:\n",
    "\n",
    "National Consortium for the Study of Terrorism and Responses to Terrorism (START). (2018). Global Terrorism Database [Data file]. Retrieved from https://www.start.umd.edu/gtd.\n",
    "\n",
    "It is a rich dataset with numerous variables and plenty of opportunities for analysis.  In this project, we will focus on predicting the 'success' of attacks which are related to cyber-events or have consequences for cyber-infrastructure (we will describe these characteristics in further detail below.   \n",
    "\n",
    "To begin, we will take a look at how this study classifies a successful terrorist attack and distinguishes it from an unsuccessful attack.  Below, is their description from pages 11 and 26 of their code-book (__[GTD Global Terrorism Database. Codebook: Inclusion Criteria and Variables](http://www.start.umd.edu/gtd/downloads/Codebook.pdf)__):\n",
    "\n",
    "> \"The GTD does not include plots or conspiracies that are not enacted, or at least attempted. For\n",
    "an event to be included in the GTD, the attackers must be “out the door,” en route to execute\n",
    "the attack. Planning, reconnaissance, and acquiring supplies do not meet this threshold.\n",
    "The GTD does include attacks that were attempted but ultimately unsuccessful. The\n",
    "circumstances vary depending on tactics (for details see the success variable, below). However,\n",
    "in general if a bomb is planted but fails to detonate; if an arsonist is intercepted by authorities\n",
    "before igniting a fire; or, if an assassin attempts and fails to kill his or her intended target, the\n",
    "attack is considered for inclusion in the GTD, and marked success=0.\" P. 11\n",
    "\n",
    "> \"Success of a terrorist strike is defined according to the tangible effects of the attack.\n",
    "Success is not judged in terms of the larger goals of the perpetrators. For example, a\n",
    "bomb that exploded in a building would be counted as a success even if it did not\n",
    "succeed in bringing the building down or inducing government repression.\n",
    "The definition of a successful attack depends on the type of attack. Essentially, the\n",
    "key question is whether or not the attack type took place. If a case has multiple\n",
    "attack types, it is successful if any of the attack types are successful, with the\n",
    "exception of assassinations, which are only successful if the intended target is killed.\n",
    "        1 = \"Yes\" The incident was successful.\n",
    "        0 = \"No\" The incident was not successful.\" P. 26\n",
    "\n",
    "Thus, our focus below will be on using the data collected to build a model which will successfully predict the success of a terror attack.  Below, we will begin importing and working with our data, and explanations and analysis will follow when pertinent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as skl\n",
    "import gc\n",
    "import sys\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1. Importing, Cleaning and General Overview:\n",
    "\n",
    "#### A. Importing Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('globalterrorismdb_0718dist.xlsx', \n",
    "                   usecols = 'A, I, K, M, S:W, AA:AB, AD, AJ, AL, AM, AN, AP, BG, BM:BN, BQ, CE, CG, DA',\n",
    "                   dtype = {'summary':str, 'motive':str})                                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Renaming our columns for usability:\n",
    "\n",
    "cyber_data = pd.DataFrame(df.rename({'eventid':'event_id', 'doubtterr':'doubt', 'attacktype1_txt':'attack_1txt', \n",
    "                                     'targtype1_txt':'target_1txt', 'targsubtype1':'sub_target',\n",
    "                                     'targsubtype1_txt':'sub_targettxt', 'target1':'specific_target',\n",
    "                                     'natlty1_txt':'victim_nationalitytxt', 'gname':'group_name', \n",
    "                                     'guncertain1':'group_attrib_crtainty', 'individual':'unaffil_individ', \n",
    "                                     'weaptype1':'weapon', 'weaptype1_txt':'weapontxt', \n",
    "                                     'weapsubtype1':'sub_weapon', 'weapsubtype1_txt':'sub_weapontxt'}, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363453"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Memory Mitigation:\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181691, 24)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyber_shape_1 = cyber_data.shape\n",
    "cyber_shape_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### B. Selecting Rows Specific to Cyber-Related Terrorism:\n",
    "\n",
    "In order to filter the dataset and focus our inquiry on cyber-related events, we will use the following regex statements.  This statement attempts to focus on communication platforms (cellular, internet, radio) and its infrastructure (to a certain extent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# no 'Unknown' values.\n",
    "specific = cyber_data.specific_target.str.contains(r'(internet|cell+|radio|communic+|emai+|cyb+|web|hac+)', \n",
    "                                                   na = 'Unknown', flags = re.IGNORECASE)\n",
    "specific_true = specific.loc[specific == True].keys()\n",
    "specific_unknown = specific.loc[specific == 'Unknown'].keys()\n",
    "\n",
    "# no 'Unknown' values.\n",
    "motive = cyber_data.motive.str.contains(r'(internet|cell+|radio|comm+|infor+|emai+|cyb+|web|hac+)', \n",
    "                                        na = 'Unknown', flags = re.IGNORECASE)\n",
    "motive_true = motive.loc[motive == True].keys()\n",
    "\n",
    "# no 'Unknown' values.\n",
    "summary = cyber_data.summary.str.contains(r'(internet|cell+|radio|comm+|infor+|emai+|cyb+|web|hac+)', \n",
    "                                          na = 'Unknown', flags = re.IGNORECASE)\n",
    "summary_true = summary.loc[summary == True].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13255, 24)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining the above results into a dataframe and looking at the shape:\n",
    "\n",
    "cyber_data = cyber_data.loc[(cyber_data.index.isin(specific_true)) | (cyber_data.index.isin(motive_true)) | \n",
    "                          (cyber_data.index.isin(summary_true)) | (cyber_data.index.isin(specific_unknown))]\n",
    "\n",
    "\n",
    "cyber_shape_2 = cyber_data.shape\n",
    "cyber_shape_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### C. Splitting Our Train/Test Data:\n",
    "\n",
    "Below, we dropped some specific columns in dataframe in order to make future processing more efficient.  The 'event_id' column wasn't numerically significant and created problems when getting dummies was necessary. The same occured with 'summary' and 'motive.'  These last two columns, however, will come in handy when considering avenues for further research, which we will discuss below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "# Defining our Input and Output data:\n",
    "# (Cleaning afterwards to prevent leakage)\n",
    "\n",
    "X = cyber_data.drop(['event_id', 'success', 'summary', 'motive'], axis = 1)\n",
    "Y = pd.DataFrame(cyber_data['success'])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = .25)\n",
    "\n",
    "X_train_start_index = X_train.index\n",
    "X_test_start_index = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Memory Mitigation (Resource cited below):\n",
    "\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "cleaner = sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], \n",
    "                 key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del X, Y, cleaner, specific, motive, summary, summary_true, motive_true, specific_true, specific_unknown\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### D. Isolating Columns:\n",
    "\n",
    "We want to be sure we are only using the numeric columns that are significant (i.e. binary or numerically related to the values they contain) and not arbitrary categoricals (such as using numbers to classify one instance over another).  Initially, we imported more of the dataset which included different types of data-types.  After running the notebook as it was closer to its final form, it took considerably longer to load, at which point we dropped most of these columns from our initial read-in of the data. We account for a few lingering columns below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "cyber_train_X = X_train[['country_txt', 'region_txt', 'city', 'crit1', 'crit2', 'crit3', 'doubt',\n",
    "                       'suicide', 'attack_1txt', 'target_1txt', 'sub_targettxt', 'corp1',\n",
    "                       'specific_target', 'victim_nationalitytxt', 'group_name',\n",
    "                       'group_attrib_crtainty', 'unaffil_individ', 'weapontxt',\n",
    "                       'sub_weapontxt']]\n",
    "\n",
    "# Making sure input and output dataframes still have the same amount of rows:\n",
    "\n",
    "cyber_train_Y = Y_train.iloc[Y_train.index == cyber_train_X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Applying the same process above to our test data:\n",
    "\n",
    "cyber_test_X = X_test[['country_txt', 'region_txt', 'city', 'crit1', 'crit2', 'crit3', 'doubt',\n",
    "                       'suicide', 'attack_1txt', 'target_1txt', 'sub_targettxt', 'corp1',\n",
    "                       'specific_target', 'victim_nationalitytxt', 'group_name',\n",
    "                       'group_attrib_crtainty', 'unaffil_individ', 'weapontxt',\n",
    "                       'sub_weapontxt']]\n",
    "\n",
    "cyber_test_Y = Y_test.iloc[Y_test.index == cyber_test_X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "train_shape = cyber_train_X.shape\n",
    "test_shape = cyber_test_X.shape\n",
    "print(train_shape)\n",
    "print(test_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### E. Applying Filters to Text Columns.\n",
    "\n",
    "The cells below are an attempt to consolidate (or group) some of the values together with a few certain columns we will be focusing on.  Given that these columns have a considerable number of unique values, when getting dummies later, it will greatly increase the size of our feature set.  While an increased feature-set is not necessarily a bad thing, preventing the size from becoming too large will aid in our explanatory power later on.  In other words, our feature set will have a comprehensible size, allowing us to explain the characteristics around a successful attack. Otherwise, we run the risk of a feature set which is too large for a human to understand and too many features - making it difficult to see which columns/characteristics are significant for our analysis.\n",
    "\n",
    "Below, we focus mainly on the types of weapons, the named terrorist groups and the cities attacked.  We also consolidated some of the sub_targets into larger groups.  After running our preliminary models, we found that targets and sub_targets were significant to our models, so we conducted some further feature engineering afterwards, which we will discuss later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There were a number of resources which were helpful in this grouping process, which we will lay out here:\n",
    "\n",
    "Regarding the 'weapontxt' column, which describes the type of weapons used in the attack, and the 'sub_target' column (which provides further details on the primary target) we mainly referred to the codebook accompanying the study (as mentioned above: (__[GTD Global Terrorism Database. Codebook: Inclusion Criteria and Variables](http://www.start.umd.edu/gtd/downloads/Codebook.pdf)__)).  The grouping below was rather simple - primarily placing a few types of weapon-groups and sub-targets together when it would not negatively impact our explanatory capabilites down the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The 'city' and 'group_name' columns were more technical and involved some outside research.  The groupings below are aimed at linking cities together if they fall within an ideological, religious, environmental or political umbrella in which certain terrorist groups are interested.  For example, some middle-eastern cities are considered to lean more 'Sunni' as opposed to 'Shia', while others are 'split.'  Some South American cities lie within an area experiencing heavy gang activity (such as the Northern Triangle between Mexico and Panama).  Our goal with these groupings was to combine cities whenever they had a common interest factor for terrorist events, in the hopes that it would consolidate their correlation and aid in our predictive models.  \n",
    "\n",
    "These groupings, however, can be improved upon with further in-depth research.  Our time with this project was somewhat limited and there are a handful of regions we were unable to group together or research.  Additionally, our expertise in global terrorism is slight in comparison to those working in the field, which would benefit from an expert team member when creating these filters.  That said, it would be highly interesting to continue improving these classifications, especially given the wealth of information and databases made available by respected international research organizations, which we will list here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some cities and groups were classified according to their religious leanings:\n",
    "\n",
    "- Some Middle-Eastern cities were grouped under a Sunni/Shia or Sunni/Shia Split category.  These resources were helpful in ascertaining where a city fell with respect to these religious tendencies:\n",
    "-  A New York Times article by Sarah Almukhtar, Sergio Peçanha and Tim Wallace on January 5th, 2016, entitled: __[Behind Stark Political Divisions, a More\n",
    "Complex Map of Sunnis and Shiites.](https://www.nytimes.com/interactive/2016/01/04/world/middleeast/sunni-shiite-map-middle-east-iran-saudi-arabia.html)__\n",
    "- A blog post by Olivier Ypsilantis on August 14th, 2014, entitled: __[Carte religieuse de l’Iran et ses voisins](http://zakhor-online.com/?attachment_id=7932)__.\n",
    "- Max Fisher wrote a great article for Vox on March 26th, 2015 which has a lot of great maps for reference: __[40 maps that explain the Middle East](https://www.vox.com/a/maps-explain-the-middle-east)__\n",
    "The Gulf 2000 Project has a plethora of maps and resources regarding issues in the Middle-East, and specifically this page by Dr. Michael Izady entitled __[Atlas of the Islamic World and Vicinity\n",
    "(Infographs, Maps and Statistics Collection).](http://gulf2000.columbia.edu/maps.shtml)__ Some other maps we used from this site were: - __[A map of West Africa](http://gulf2000.columbia.edu/images/maps/West_Africa_Religion_lg.png)__\n",
    " - __[A map of Libya](http://gulf2000.columbia.edu/images/maps/Libya_Religion_Western_Sector_lg.png)__\n",
    " - __[A Shia territories map](http://gulf2000.columbia.edu/images/maps/ShiasReligionCore_lg.png)__\n",
    "\n",
    "The Crisis Group also has a number of useful resources and articles regarding these topics.  Specifically regarding Colombia and South America, we referenced and article entitled __[Colombia’s Armed Groups Battle for the Spoils of Peace](https://www.crisisgroup.org/latin-america-caribbean/andes/colombia/63-colombias-armed-groups-battle-spoils-peace)__ from Report  63 / Latin America & Caribbean 19 OCTOBER 2017.  There was an interesting map by Mike Shand (International Crisis Group 2017), entitled __[Map of Armed Groups and Coca Crops in Colombia, 2017.](https://www.crisisgroup.org/latin-america-caribbean/andes/colombia/63-colombias-armed-groups-battle-spoils-peace#map-5700-8)__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll also take this opportunity to list out further databases and resources we used for this project:\n",
    "\n",
    "For 'group_names' we referenced START's resources again (as they have a wealth of resources surrounding the database we used and the elements it describes.  Here, they list the names of __['Big, Allied and Dangerous' terrorist groups,](http://www.start.umd.edu/baad/database)___ which we used as the basis for a majority of our classification.\n",
    "\n",
    "The __[SATP website](http://www.satp.org/conflict-maps/bangladesh)__ was instrumental in gaining insight into Asian conflicts. Within this website, we referenced a specific article regarding the \n",
    "__[Nepalise Maoist conflicts](http://www.satp.org/terrorist-profile/nepal/communist-party-of-nepal-maoist)__, which described their objectives, operating areas, leaders, etc.  Towards the bottom of the page, it includes a ranking by the Nepalese Home Ministry, of areas in Nepal according to their sensitivity to these issues.  We then used this __[map](https://reliefweb.int/map/nepal/nepal-regions-zones-and-districts-cities-april-2015)__ from ReliefWeb to help us locate smaller cities in pertinent areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "South America and the Northern Triangle:\n",
    "\n",
    "Again, there are a number of databases and materials available from top-level international organizations.  Regarding the Northern Triangle (namely Guatemala, Honduras, El Salvador) we referenced the following articles:\n",
    " - __[Central America’s Violent Northern Triangle](https://www.cfr.org/backgrounder/central-americas-violent-northern-triangle)__By Rocio Cara Labrador and Danielle Renwick (updated June 26th, 2018) \n",
    " - The Insight Crime Organiztion has a main page for each country involved in frequent conflicts__[such as this one regarding El Salvador](https://www.insightcrime.org/el-salvador-organized-crime-news/)__   \n",
    " - Relief Web also had a variety of resources we used here, specifically a __[main search page](https://reliefweb.int/country/slv)__ for each country that leads to reports, infographics and the like.\n",
    " - The __[Humanitarian Reponse Group](https://www.humanitarianresponse.info/en/infographics)__ also has great resources and infographics.\n",
    " - The __[United Nations Regional Information Centre](https://www.unric.org/en/databases/26912-refugees-humanitarian-affairs-and-migration)__ points to a number of outside resources depending on what one is looking for.\n",
    " - In refrencing hotspots of violence in Guatemala, we used Relief Web's summary on __[Humanitarian Needs Overview for Guatemala in 2017](https://reliefweb.int/sites/reliefweb.int/files/resources/20180315_SUMMARY_HNO%20GT_ENG.pdf)__\n",
    " - Regarding the same of El Salvador, we used Relief Web's __[Map of El Salvador.](https://reliefweb.int/sites/reliefweb.int/files/resources/20180405%20monthly%20humanitarian%20snapshot%20-%20ENG.pdf)__\n",
    " - For Honduras we referred to an article entitled __['Northern Triangle is World's Extortion Hotspot'](https://www.insightcrime.org/news/brief/northern-triangle-world-extortion-hotspot/)__ by Steven Dudley and Michael Lohmuller on JULY 1st, 2015.  This article has a map that was helpful in locating our cities.\n",
    " - Regarding Columbia, we frequently referred to the __[Crisis Group's resources.](https://www.crisisgroup.org/)__ \n",
    "There were two articles in particular we referred to here.  The first was entitled 'Colombia’s Armed Groups Battle for the Spoils of Peace' (which we already referenced above).  The second was a map entitled __['Map of ELN Presence in Colombia in 2012 and 2018, and Expansion between 2012 and 2018'](https://www.crisisgroup.org/latin-america-caribbean/andes/colombia/68-missing-peace-colombias-new-government-and-last-guerrillas#map-6189-1)__ within an article named __['The Missing Peace: Colombia’s New Government and Last Guerrillas'](https://www.crisisgroup.org/latin-america-caribbean/andes/colombia/68-missing-peace-colombias-new-government-and-last-guerrillas)__ from their Report 68 / Latin America & Caribbean on July 12th, 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Other General References include:\n",
    "\n",
    " - __[Homeland Security Digital Library](https://www.hsdl.org/?collection&id=2167)__\n",
    " - __[U Mass Lowell](https://www.uml.edu/Research/CTSS/Online-Resources.aspx)__ Has a great page with links to further resources.\n",
    " - The Council on Foreign Relations has a page entitled __[Invisible Armies Insurgency Tracker: A Visual History of Guerrilla Warfare From 1775 to 2012 (from April 18th, 2013](https://www.cfr.org/wars-and-warfare/invisible-armies-insurgency-tracker/p29917)__.  As they describe it at the top of the page: \"The interactive Invisible Armies Insurgency Tracker presents a database of insurgencies from 1775 to 2012. It supplements the comprehensive historical narrative in Invisible Armies: An Epic History of Guerrilla Warfare from Ancient Times to the Present, by CFR Senior Fellow Max Boot.\"\n",
    " - West Point has __[The Combating Terrorism Center](https://ctc.usma.edu/regions/middle-east/)__ which is incredibly helpful and insightful with their background information.\n",
    " - __[The Terrorism Research and Analysis Consortium](https://www.trackingterrorism.org/region/afghanistan)__ has a lot of information - mostly private and paid, but one can at least browse the surface of what they offer (we also used some of their 'vulnerable cities' classifications in our cells below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### 1. Defining Categories for Values within 'Sub_targettxt', 'Group_Name' and 'City':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Here is the function we will use to take our list of values and replace it with specific group/category names:\n",
    "    # We will do this for each of the test and training sets:\n",
    "    \n",
    "def magic_value_replacer(df, column, variable, string):\n",
    "    \n",
    "    df[column] = df[column].replace(variable, string)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "###### Sub_targettxt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "industrial = ['Gas/Oil/Electric', 'Industrial/Textiles/Factory', 'Farm/Ranch', 'Mining', 'Construction']\n",
    "\n",
    "white_collar = ['Restaurant/Bar/Café', 'Bank/Commerce', 'Multinational Corporation', \n",
    "                'Medical/Pharmaceutical', 'Retail/Grocery/Bakery (including cell phone shops and generic shops)', \n",
    "                'Hotel/Resort', 'Entertainment/Cultural/Stadium/Casino', 'Private Security Company/Firm',\n",
    "                'Legal Services', 'Retail/Grocery/Bakery']\n",
    "\n",
    "gov_figure1 = ['Judges/Attorneys/Courts', 'Judge/Attorney/Court', \n",
    "               'Government Personnel (excluding police, military)']\n",
    "\n",
    "gov_figure2 = ['Politician or Political Party Movement/Meeting/Rally', 'Royalty', 'Head of State',\n",
    "               'Election Related', 'Election-related']\n",
    "\n",
    "pol_facilities = ['Police Buildings (Headquarters/Stations/School)', \n",
    "                  'Police Patrol (including vehicles and convoys)', 'Police Checkpoint', 'Prison/Jail', \n",
    "                  'Police Building (headquarters, station, school)']\n",
    "\n",
    "mil_facilities = ['Military Barracks/Base/Headquarters/Checkpost', 'Military Recruiting Station/Academy',\n",
    "                       'Military Weaponry', 'Military Aircraft', 'Military Maritime', 'Paramilitary', \n",
    "                       'Military Transportation/Vehicle (excluding convoys)', 'Military Checkpoint']\n",
    "\n",
    "mil_personnel = ['Military Unit/Patrol/Convoy', 'Non-combatant Personnel', \n",
    "                      'Military Personnel (soldiers, troops, officers, forces)']\n",
    "\n",
    "gov_diplomatic = ['Diplomatic Personnel (outside of embassy, consulate)', 'Embassy/Consulate', 'NATO', \n",
    "                  'International Organization (peacekeeper, aid agency, compound)']\n",
    "\n",
    "educational = ['Teacher/Professor/Instructor', 'School/University/Educational Building', 'Other Personnel']\n",
    "\n",
    "food_water = ['Food Supply', 'Water Supply']\n",
    "\n",
    "internet_comm_information = ['Newspaper Journalist/Staff/Facility', 'Radio Journalist/Staff/Facility', \n",
    "                             'Television Journalist/Staff/Facility', 'Other (including online news agencies)',\n",
    "                             'Radio', 'Internet Infrastructure', 'Television', 'Electricity', \n",
    "                             'Telephone/Telegraph']\n",
    "\n",
    "religious = ['Religion Identified', 'Religious Figure', 'Place of Worship', 'Affiliated Institution']\n",
    "\n",
    "political = ['Protrainer', 'Political Party Member/Rally', 'Party Official/Candidate/Other Personnel', \n",
    "             'Party Office/Facility', 'Rally']\n",
    "\n",
    "mass_socio = ['Refugee (including Camps/IDP/Asylum Seekers)', 'Named Civilian', 'Student', \n",
    "              'Race/Ethnicity Identified', 'Farmer', 'Vehicles/Transportation', 'Marketplace/Plaza/Square', \n",
    "              'Village/City/Town/Suburb', 'House/Apartment/Residence', 'Laborer (General)/Occupation Identified', \n",
    "              'Procession/Gathering (funeral, wedding, birthday, religious)', 'Civilian Maritime',\n",
    "              'Public Areas (e.g., Public garden, parking lot, garage, beach, public buildings, camps)',\n",
    "              'Public Area (garden, parking lot, garage, beach, public building, camp)', 'Port', \n",
    "              'Memorial/Cemetery/Monument', 'Museum/Cultural Center/Cultural House', 'Labor Union Related', \n",
    "              'Tourism Travel Agency', 'Tour Bus/Van/Vehicle', 'Tourist', 'Other Facility', 'Airport',\n",
    "              'train/train Tracks/ Trolley', 'Bus Station/Stop', 'Subway', 'Bridge/Car Tunnel', \n",
    "              'Highway/Road/Toll/Traffic Signal', 'Taxi/Rickshaw', 'Bus (excluding tourists)', \n",
    "              'Commercial Maritime', 'Train/Train Tracks/Trolley', 'Aircraft (not at an airport)', \n",
    "              'Airline Officer/Personnel', 'Aircraft (not at an airport)', \n",
    "              'Demilitarized Zone (including Green Zone)']\n",
    "\n",
    "first_responders = ['Clinics', 'Fire Fighter/Truck', 'Ambulance']\n",
    "\n",
    "other_utilities = [ 'Gas', 'Oil', 'Oil Tanker']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "###### specific_target:\n",
    "\n",
    "There were some duplicates here that were related to what we are looking for, so I went ahead and combined them in the hopes that they might lead to some more insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "comm_related = ['Cell tower', 'Cell phone tower',  'Cell Tower', 'Cell Phone Tower', 'Cell Phone Shop',\n",
    "                'Telecommunication Tower', 'Telecommunications Tower', 'Radio Stations', 'Radio Station',\n",
    "                'Radio station', 'radio station', 'Radio station antenna', 'A mobile phone tower', \n",
    "                'A mobile tower was targeted in the attack.', 'A Globe Telecom cell site', 'Internet Cafe',\n",
    "                'Telecommunications office', 'Telecommunication Institute', 'Communications Tower', \n",
    "                'Telecommunications Mast', 'An internet cafe']\n",
    "polling_areas = ['Polling Station', 'Polling Center', 'Polling Stations', 'Polling Booth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "###### Group_name: (Grouping by Ideology, Political Tendencies, Etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "palestinian_separatists = ['Hamas (Islamic Resistance Movement)', 'Palestinian Islamic Jihad (PIJ)',\n",
    "                           'Popular Front for the Liberation of Palestine (PFLP)', 'Popular Resistance Committees',\n",
    "                           'Al-Fatah']\n",
    "\n",
    "militants = ['Militants', 'Gunmen']\n",
    "\n",
    "asian_separatists = ['Abu Sayyaf Group (ASG)', 'Colonel Karuna Faction', 'Eastern Turkistan Islamic Movement (ETIM)',\n",
    "                     'Free Aceh Movement (GAM)', 'Janatantrik Terai Mukti Morcha (Jtmm)', \n",
    "                     'Janatantrik Terai Mukti Morcha- Goit (Jtmm-G)', \n",
    "                     'Janatantrik Terai Mukti Morcha- Jwala Singh (Jtmm-J)',\n",
    "                     'Janatantrik Terai Mukti Morcha- Rajan Mukti (Jtmm-R)',\n",
    "                     'Liberation Tigers of Tamil Eelam (LTTE)', 'Moro Islamic Liberation Front (MILF)',\n",
    "                     'Runda Kumpulan Kecil (Rkk)', 'Terai Army']\n",
    "\n",
    "middle_eastern_separatists = ['Haqqani Network', 'Harkatul Jihad-E-Islami', 'Lashkar-E-Taiba (Let)',\n",
    "                             'Kurdistan Workers\\' Party (PKK)', 'Lashkar-E-Balochistan', 'Chechen Rebels',\n",
    "                             'Free Syrian Army', 'Caucasus Emirate', 'Baloch Republican Army (BRA)',\n",
    "                             'Ansar Al-Islam', 'Kurdistan Free Life Party', 'Baloch Liberation Front (Blf)',\n",
    "                             'Baloch Liberation Army (BLA)', 'Ansar Al-Sharia (Libya)', 'Jaish-E-Mohammad (Jem)',\n",
    "                             'Riyadus-Salikhin Reconnaissance And Sabotage Battalion Of Chechen Martyrs',\n",
    "                             'Hizbul Mujahideen (Hm)', 'Southern Mobility Movement (Yemen)',\n",
    "                             'Supreme Council For Islamic Revolution In Iraq (Sciri)']\n",
    "\n",
    "indian_separatists = ['Dima Halao Daoga (Dhd)', 'Black Widows', 'Garo National Liberation Army',\n",
    "                      'Kangleipak Communist Party (KCP)', 'National Democratic Front of Bodoland (NDFB)',\n",
    "                      'National Liberation Front of Tripura (NLFT)', 'People\\'s Liberation Army (PLA)',\n",
    "                      'United Liberation Front of Assam (ULFA)', 'United National Liberation Front (UNLF)',\n",
    "                      'Karbi Longri North Cachar Liberation Front (Klnlf)', \n",
    "                      'National Socialist Council of Nagaland-Isak-Muivah (NSCN-IM)',\n",
    "                      'People\\'s Revolutionary Party of Kangleipak (PREPAK)']\n",
    "\n",
    "NW_indian_groups = ['Lashkar-e-Jhangvi', 'Sipah-e-Sahaba/Pakistan (SSP)', 'Hizbul Mujahideen (HM)', \n",
    "                    'Baloch Liberation Front (BLF)', 'Baloch Young Tigers (BYT)', 'Baloch Young Tigers (BYT)',\n",
    "                    'Baloch Liberation Army (BLA)', 'Baloch Republican Army (BRA)', 'United Baloch Army (UBA)',\n",
    "                    'Free Balochistan Army (FBA)', 'Baloch Nationalists']\n",
    "\n",
    "SE_indian_groups = ['Communist Party of India - Maoist (CPI-Maoist)', 'Indian Mujahideen', \n",
    "                    'Jama\\'atul Mujahideen Bangladesh (JMB)', 'Bangladesh Sarbahara Party',\n",
    "                    'Purbo Banglar Communist Party', 'Harkatul Jihad-e-Islami',\n",
    "                    'National Socialist Council of Nagaland-Unification (NSCN-U)',\n",
    "                    'Kanglei Yawol Kanna Lup (KYKL)', 'Kuki Tribal Militants', 'Kuki National Front (KNF)',\n",
    "                    'United Kuki Liberation Front (UKLF) - India', 'Hill Tiger Force (HTF)',\n",
    "                    'National Socialist Council of Nagaland-Khaplang (NSCN-K)',\n",
    "                    'National Socialist Council of Nagaland-Isak-Muivah (NSCN-IM)',\n",
    "                    'Hynniewtrep National Liberation Council (HNLC)']\n",
    "\n",
    "african_political = ['National Union for the Total Independence of Angola (UNITA)']\n",
    "\n",
    "irish_separatists = ['Real Irish Republican Army (RIRA)', 'Oglaigh Na Heireann', 'Irish Republican Army (IRA)']\n",
    "\n",
    "FARC_left_right = ['National Liberation Army of Colombia (ELN)', 'Popular Liberation Army (EPL)',\n",
    "                   'Revolutionary Armed Forces of Colombia (FARC)', 'United Self Defense Units of Colombia (AUC)']\n",
    "\n",
    "middle_eastern_religious = ['Al-Gama\\'at Al-Islamiyya (IG)', 'Al-Nusrah Front', 'Al-Qa\\'ida',\n",
    "                            'Al-Qa\\'ida in the Arabian Peninsula (AQAP)', 'Al-Shabaab', 'Ansar Al-Islam',\n",
    "                            'Ansar Al-Sharia (Libya)', 'Al-Qa\\'ida in the Lands of the Islamic Maghreb (AQLIM)',\n",
    "                            'Asa\\'Ib Ahl Al-Haqq', 'Caucasus Emirate', 'Eritrean Islamic Jihad Movement (EIJM)',\n",
    "                            'Great Eastern Islamic Raiders Front (Ibda-C)', 'Hizbul Al Islam (Somalia)',\n",
    "                            'Islamic Courts Union (ICU)', 'Islamic State of Iraq and al Sham (ISIS)',\n",
    "                            'Islamic Movement of Uzbekistan (IMU)', 'Jamiat Ul-Mujahedin (Jum)',\n",
    "                            'Jundallah', 'Mahdi Army', 'Taliban', 'Tehrik-i-Taliban Pakistan (TTP)', \n",
    "                            'Muslim extremists', 'Armed Islamic Group (GIA)', 'Sunni Muslim extremists',\n",
    "                            'Al-Qaida in the Islamic Maghreb (AQIM)', 'Al-Qaida', 'Al-Qaida in Iraq', \n",
    "                            'Islamic State of Iraq and the Levant (ISIL)',\n",
    "                            'Al-Qaida in the Arabian Peninsula (AQAP)']\n",
    "\n",
    "israel_palestine_lebanon = ['Anti-Semitic extremists', 'Hezbollah']\n",
    "\n",
    "asian_african_religious = ['Students Islamic Movement of India (Simi)', 'Ranbir Sena', 'Jemaah Islamiya (JI)', \n",
    "             'Movement for Oneness and Jihad in West Africa (MUJAO)', 'Lord\\'s Resistance Army (LRA)',\n",
    "             'Boko Haram']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "###### City: (Grouping by Predominate Religion, Political Party or Conflict Issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sunni_cities = ['Mosul', 'Kirkuk', 'Sanandaj', 'Ramadi', 'Trabzone', 'Diarbekir', \n",
    "                'Damascus', 'Gwadar', 'Zahedan', 'Kandahar', 'Khiva', 'Fallujah',\n",
    "                'Dakhla', 'Tajura', 'Sabrata', 'Azizia', 'Kasabat', 'Misrata', 'Tripoli',\n",
    "                'Takrit', 'Tikrit']\n",
    "\n",
    "shia_cities = ['Mecca', 'Najaf', 'Karbala', 'Samarra', 'Ahwaz', 'Basra', \n",
    "               'Medina', 'Tabriz', 'Tunceli', 'Zahran', 'Tehran', 'Rasht', 'Bojnurd',\n",
    "               'Hillah', 'Diwania', 'Khalis', 'Dujali', 'Balad', 'Khanaqin', \n",
    "               'Sargodha', 'Dadu', 'Moro']\n",
    "\n",
    "split_cities = ['Kirmanshah', 'Baghdad', 'Kadhimia', 'Kuwait', 'Kars', 'Maras', \n",
    "               'Ankara', 'Sivas', 'Aleppo', 'Beirut', 'Abha', 'Jizan', 'Qazvin',\n",
    "               'Gunbad', 'Ashgabat', 'Mashhad', 'Herat', 'Merv', 'Charju', 'Bukhara',\n",
    "               'Samarkand', 'Mazari Sharif', 'Kandahar', 'Lar', 'Bandar Abbas', 'Dubai', \n",
    "               'Abu Dhabi', 'Tashkent', 'Erzurum', 'Konya', 'Izmir', 'Bursa', 'Istanbul',\n",
    "               'Tarhuna', ]\n",
    "\n",
    "ibadi_cities_libya = ['Nalut', 'Zentan', 'Gharian', 'Dafnia', 'Abu Kammash', 'Zuwara']\n",
    "\n",
    "columbia_eln_cities = ['Riosucio', 'Buenaventura', 'Cali', 'Popayán', 'Bucaramanga',\n",
    "                       'Barrancabermeja', 'Cucuta', 'Santa Rita']\n",
    "\n",
    "maoist_insurgency = ['Bhagalpur', 'Arwal', 'Khagaria', 'Rohtas', 'Kaimur',\n",
    "                       'Bhabua', 'Munger', 'Monghyr', 'Vaishali',\n",
    "                    'Dhanbad', 'Pakur', 'Koderma', 'Palamu', 'Balaghat',\n",
    "                     'Katni', 'Khandwa', 'Rajgarh', 'Shajapur']\n",
    "\n",
    "w_africa_muslim = ['Touba', 'N\\'Djamena', 'Maiduguri', 'Zaria', 'Sokoto', 'Kenema',\n",
    "                   'Cetoua', 'Mopte', 'Bobo-Dioulasso', 'Kayes', 'Monrovia']\n",
    "\n",
    "w_africa_mixed = ['Dogondutchi', 'Niamey', 'Parakou', 'Abuja', 'Kaduna', 'Kankan',\n",
    "                  'Lagos', 'Port Harcourt', 'Couala', 'Yaounde', 'Kumasi', 'Bamako',\n",
    "                  'Bertoua', 'Liberville', 'Port-Gentil', 'Zinder', 'Ouagadougou',\n",
    "                  'Freetown', 'Conakry', 'Bissau', 'Banjul', 'Dakar']\n",
    "\n",
    "w_africa_christian = ['Benin City', 'Onitsha', 'Abidjan', 'Takoradi', 'Accra', 'Lome']\n",
    "\n",
    "\n",
    "# Nepal Maoist Conflict - Class A According to SATP\n",
    "Nepal_maoist_A = ['Musikot', 'Rukumkot', 'Jajarkot District', 'Salyan', 'Pyuthan', 'Gajul', 'Rank', 'Budagaun',\n",
    "                  'Kalikot District', 'Rolpa', 'Rolpa District', 'Rukum District', 'Khalanga']\n",
    "\n",
    "# Nepal Maoist Conflict - Class B According to SATP\n",
    "Nepal_maoist_B = ['Charikot', 'Dolakha', 'Jiri', 'Ramechhap', 'Sindhuli Garhi', 'Sindhuli District', 'Dhungrebas',\n",
    "                  'Panaoti', 'Gorkha', 'Tulsipur', 'Ghorahi', 'Surkhet', 'Birendranagar',\n",
    "                  'Accham', 'Kamal Bajar', 'Dang', 'Dang District']\n",
    "\n",
    "# Nepal Maoist Conflict - Class C According to SATP\n",
    "Nepal_maoist_C = ['Khotang Bajar', 'Khotang District', 'Khandanda', 'Okhaldhunga', 'Rumjatar', 'Udayapur Garhi',\n",
    "                  'Rasuwa District', 'Gaighat', 'Hitura', 'Makwanpur Garhi', 'Patan', 'Baglung', 'Dhorpatan',\n",
    "                  'Bardiya', 'Gulariya', 'Dailekh', 'Dailekh District', 'Jumla', 'Dhading District', \n",
    "                  'Udayapur District', 'Lalitpur', 'Hetauda', 'Gulariya']\n",
    "\n",
    "\n",
    "# N_Triangle_S.America:\n",
    "northern_triangle = ['Tegucigalpa', 'San Pedro Sula', 'Guatemala City', 'Villa Nueva', 'Villa Canales', \n",
    "                     'Mixco', 'San Jan Sacatepequez', 'Chinautla', 'Escuintla', 'Jalapa', 'Puerto Barrios', \n",
    "                     'Morales', 'La Libertad', 'Nueva Concepcion', 'Metapan', 'Acajutla', 'Sonsonate',\n",
    "                     'Izalco', 'San Salvador', 'Apopa', 'Zaragoza', 'Colon', 'Santa Tecla', 'Usulutan',\n",
    "                     'San Miguel', 'La Union']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### 2. Implementing the Filtering Function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "###### Sub_targettxt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', industrial, 'Industrial')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', white_collar, 'White_collar')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', gov_figure1, 'Gov_Figure1')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', gov_figure2, 'Gov_Figure2')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', pol_facilities, 'Police_Facilities')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', mil_facilities, 'Military_Facilities')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', mil_personnel, 'Military_Personnel')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', gov_diplomatic, 'Gov_Diplomatic')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', educational, 'Educational')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', food_water, 'Food_Water')\n",
    "# magic_value_replacer(cyber_train_X, 'sub_targettxt', internet_comm_information, 'Info/Comm/Internet')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', religious, 'Religious')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', political, 'Political')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', mass_socio, 'Mass_Socio')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', first_responders, 'First_Responders')\n",
    "magic_value_replacer(cyber_train_X, 'sub_targettxt', other_utilities, 'Other_Utilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', industrial, 'Industrial')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', white_collar, 'White_collar')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', gov_figure1, 'Gov_Figure1')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', gov_figure2, 'Gov_Figure2')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', pol_facilities, 'Police_Facilities')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', mil_facilities, 'Military_Facilities')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', mil_personnel, 'Military_Personnel')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', gov_diplomatic, 'Gov_Diplomatic')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', educational, 'Educational')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', food_water, 'Food_Water')\n",
    "# magic_value_replacer(cyber_test_X, 'sub_targettxt', internet_comm_information, 'Info/Comm/Internet')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', religious, 'Religious')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', political, 'Political')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', mass_socio, 'Mass_Socio')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', first_responders, 'First_Responders')\n",
    "magic_value_replacer(cyber_test_X, 'sub_targettxt', other_utilities, 'Other_Utilities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "###### Specific_target: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "magic_value_replacer(cyber_train_X, 'specific_target', comm_related, 'Comm-Related')\n",
    "magic_value_replacer(cyber_train_X, 'specific_target', polling_areas, 'Polling_Areas')\n",
    "\n",
    "magic_value_replacer(cyber_test_X, 'specific_target', comm_related, 'Comm-Related')\n",
    "magic_value_replacer(cyber_test_X, 'specific_target', polling_areas, 'Polling_Areas')\n",
    "\n",
    "# Also applying this to cyber_data for some visualizations:\n",
    "magic_value_replacer(cyber_data, 'specific_target', comm_related, 'Comm-Related')\n",
    "magic_value_replacer(cyber_data, 'specific_target', polling_areas, 'Polling_Areas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "###### Group_name: (Grouping by Ideology, Political Tendencies, Etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "magic_value_replacer(cyber_train_X, 'group_name', palestinian_separatists, 'Palestinian_Separatists')\n",
    "magic_value_replacer(cyber_train_X, 'group_name', militants, 'Militants')\n",
    "magic_value_replacer(cyber_train_X, 'group_name', asian_separatists, 'Asian_Separatists')\n",
    "magic_value_replacer(cyber_train_X, 'group_name', middle_eastern_separatists, 'Middle_Eastern_Separatists')\n",
    "magic_value_replacer(cyber_train_X, 'group_name', indian_separatists, 'Indian_Separatists')\n",
    "magic_value_replacer(cyber_train_X, 'group_name', NW_indian_groups, 'NW_Indian_Groups')\n",
    "magic_value_replacer(cyber_train_X, 'group_name', SE_indian_groups, 'NW_Indian_Groups')\n",
    "magic_value_replacer(cyber_train_X, 'group_name', african_political, 'African_Political')\n",
    "magic_value_replacer(cyber_train_X, 'group_name', irish_separatists, 'Irish_Separatists')\n",
    "magic_value_replacer(cyber_train_X, 'group_name', FARC_left_right, 'FARC_left_right')\n",
    "magic_value_replacer(cyber_train_X, 'group_name', middle_eastern_religious, 'Middle_Eastern_Religious')\n",
    "magic_value_replacer(cyber_train_X, 'group_name', israel_palestine_lebanon, 'Israel_Palestinian_Lebanon')\n",
    "magic_value_replacer(cyber_train_X, 'group_name', asian_african_religious, 'Asian_African_Religious')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "magic_value_replacer(cyber_test_X, 'group_name', palestinian_separatists, 'Palestinian_Separatists')\n",
    "magic_value_replacer(cyber_test_X, 'group_name', militants, 'Militants')\n",
    "magic_value_replacer(cyber_test_X, 'group_name', asian_separatists, 'Asian_Separatists')\n",
    "magic_value_replacer(cyber_test_X, 'group_name', middle_eastern_separatists, 'Middle_Eastern_Separatists')\n",
    "magic_value_replacer(cyber_test_X, 'group_name', indian_separatists, 'Indian_Separatists')\n",
    "magic_value_replacer(cyber_test_X, 'group_name', NW_indian_groups, 'NW_Indian_Groups')\n",
    "magic_value_replacer(cyber_test_X, 'group_name', SE_indian_groups, 'NW_Indian_Groups')\n",
    "magic_value_replacer(cyber_test_X, 'group_name', african_political, 'African_Political')\n",
    "magic_value_replacer(cyber_test_X, 'group_name', irish_separatists, 'Irish_Separatists')\n",
    "magic_value_replacer(cyber_test_X, 'group_name', FARC_left_right, 'FARC_left_right')\n",
    "magic_value_replacer(cyber_test_X, 'group_name', middle_eastern_religious, 'Middle_Eastern_Religious')\n",
    "magic_value_replacer(cyber_test_X, 'group_name', israel_palestine_lebanon, 'Israel_Palestinian_Lebanon')\n",
    "magic_value_replacer(cyber_test_X, 'group_name', asian_african_religious, 'Asian_African_Religious')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "###### City: (Grouping by Predominate Religion, Political Party or Conflict Issue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "magic_value_replacer(cyber_train_X, 'city', sunni_cities, 'Sunni_Cities')\n",
    "magic_value_replacer(cyber_train_X, 'city', shia_cities, 'Shia_Cities')\n",
    "magic_value_replacer(cyber_train_X, 'city', split_cities, 'Split_Cities')\n",
    "magic_value_replacer(cyber_train_X, 'city', ibadi_cities_libya, 'Ibadi_Cities_Libya')\n",
    "magic_value_replacer(cyber_train_X, 'city', columbia_eln_cities, 'Columbia_ELN_Cities')\n",
    "magic_value_replacer(cyber_train_X, 'city', maoist_insurgency, 'Maoist_Insurgency')\n",
    "magic_value_replacer(cyber_train_X, 'city', w_africa_muslim, 'W_Africa_muslim')\n",
    "magic_value_replacer(cyber_train_X, 'city', w_africa_mixed, 'W_Africa_mixed')\n",
    "magic_value_replacer(cyber_train_X, 'city', w_africa_christian, 'W_Africa_christian')\n",
    "magic_value_replacer(cyber_train_X, 'city', Nepal_maoist_A, 'Nepal_Maoist_A')\n",
    "magic_value_replacer(cyber_train_X, 'city', Nepal_maoist_B, 'Nepal_Maoist_B')\n",
    "magic_value_replacer(cyber_train_X, 'city', Nepal_maoist_C, 'Nepal_Maoist_C')\n",
    "magic_value_replacer(cyber_train_X, 'city', northern_triangle, 'Northern_Triangle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "magic_value_replacer(cyber_test_X, 'city', sunni_cities, 'Sunni_Cities')\n",
    "magic_value_replacer(cyber_test_X, 'city', shia_cities, 'Shia_Cities')\n",
    "magic_value_replacer(cyber_test_X, 'city', split_cities, 'Split_Cities')\n",
    "magic_value_replacer(cyber_test_X, 'city', ibadi_cities_libya, 'Ibadi_Cities_Libya')\n",
    "magic_value_replacer(cyber_test_X, 'city', columbia_eln_cities, 'Columbia_ELN_Cities')\n",
    "magic_value_replacer(cyber_test_X, 'city', maoist_insurgency, 'Maoist_Insurgency')\n",
    "magic_value_replacer(cyber_test_X, 'city', w_africa_muslim, 'W_Africa_muslim')\n",
    "magic_value_replacer(cyber_test_X, 'city', w_africa_mixed, 'W_Africa_mixed')\n",
    "magic_value_replacer(cyber_test_X, 'city', w_africa_christian, 'W_Africa_christian')\n",
    "magic_value_replacer(cyber_test_X, 'city', Nepal_maoist_A, 'Nepal_Maoist_A')\n",
    "magic_value_replacer(cyber_test_X, 'city', Nepal_maoist_B, 'Nepal_Maoist_B')\n",
    "magic_value_replacer(cyber_test_X, 'city', Nepal_maoist_C, 'Nepal_Maoist_C')\n",
    "magic_value_replacer(cyber_test_X, 'city', northern_triangle, 'Northern_Triangle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Mitigating some memory issues:\n",
    "\n",
    "del industrial, white_collar, gov_figure1, gov_figure2, pol_facilities, mil_facilities, mil_personnel\n",
    "del gov_diplomatic, educational, food_water, internet_comm_information, religious, political, mass_socio, \n",
    "del sunni_cities, shia_cities, split_cities, ibadi_cities_libya, columbia_eln_cities, maoist_insurgency\n",
    "del w_africa_muslim, w_africa_mixed, w_africa_christian, Nepal_maoist_A, Nepal_maoist_B, Nepal_maoist_C\n",
    "del northern_triangle, african_political, asian_separatists, middle_eastern_separatists, first_responders\n",
    "del FARC_left_right, middle_eastern_religious, israel_palestine_lebanon, asian_african_religious, militants\n",
    "del indian_separatists, NW_indian_groups, SE_indian_groups, irish_separatists, palestinian_separatists, \n",
    "del other_utilities, comm_related, polling_areas\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "cleaner = sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], \n",
    "                 key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2. Preliminary Visualizations and Exploration:\n",
    "\n",
    "Here we take a look at some of the correlations and relationships between our features/columns and see what we might want to focus on with our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "success_class_balance = pd.DataFrame(cyber_data['success'].value_counts())\n",
    "cyber_data_description = pd.DataFrame(cyber_data.describe())\n",
    "\n",
    "cyber_data_objects = pd.DataFrame(cyber_data.dtypes.loc[cyber_data.dtypes == 'O'])\n",
    "cyber_data_ints = pd.DataFrame(cyber_data.dtypes.loc[cyber_data.dtypes == 'int64'])\n",
    "cyber_data_floats = pd.DataFrame(cyber_data.dtypes.loc[cyber_data.dtypes == 'float'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "variables": {
     "success_class_balance": {}
    }
   },
   "source": [
    "Based on our look at value counts, it looks like we will need to keep our class imbalance in mind as we continue.  Once we get to running our models, we will use a balanced accuracy score in order to evaluate our model with a more accurate perspective. \n",
    "\n",
    "{{success_class_balance}}\n",
    "\n",
    "The descriptive statistics below give us a nice layout of our more common values for each feature, number of unique values and their distributions as well.  After this, it looks as if our feature object types are relatively workable.  We should be fine in that regard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "variables": {
     "cyber_data_description": {}
    }
   },
   "source": [
    "> Descriptive Statistics:\n",
    "{{cyber_data_description}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "variables": {
     "cyber_data_floats": {},
     "cyber_data_ints": {},
     "cyber_data_objects": {}
    }
   },
   "source": [
    "<head>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> {{cyber_data_objects}} </td>\n",
    "            <td> {{cyber_data_ints}} </td>\n",
    "            <td> {{cyber_data_floats}} </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</head>\n",
    "          \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### B. Correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (11, 9))\n",
    "ax1 = sns.heatmap(cyber_data.corr(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### C. Most Active Groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Most prolific groups:\n",
    "\n",
    "actives = cyber_train_X['group_name'].value_counts().head(11).drop('Unknown')\n",
    "mask3 = cyber_train_X['group_name'].map(lambda x: x in actives)\n",
    "actives_df = cyber_train_X[mask3]\n",
    "\n",
    "temp_output = cyber_train_Y.loc[actives_df.index]\n",
    "\n",
    "beta_1 = actives.keys()\n",
    "gamma_1 = actives.values\n",
    "\n",
    "# Most affected countries:\n",
    "\n",
    "hot_countries = cyber_train_X['country_txt'].value_counts().head(10)\n",
    "mask3 = cyber_train_X['country_txt'].map(lambda x: x in hot_countries)\n",
    "hot_countries_df = cyber_train_X[mask3]\n",
    "phi = hot_countries_df['country_txt'].value_counts().head(10)\n",
    "\n",
    "temp_output2 = cyber_train_Y.loc[hot_countries_df.index]\n",
    "\n",
    "\n",
    "beta_2 = phi.keys()\n",
    "gamma_2 = phi.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize = (17, 7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "ax1 = sns.pointplot(x = actives_df['group_name'], y = temp_output['success'])\n",
    "ax1.set_xticklabels(labels = beta_1, rotation = '80', fontdict = {'fontsize':10})\n",
    "ax1.set_xlabel('Name of Terrorist Group', fontdict = {'fontsize':12})\n",
    "ax1.set_ylabel('Success Rate', fontdict = {'fontsize':12})\n",
    "ax1.set_title('Most Active Terror Groups and Their Success Rates')\n",
    "plt.subplots_adjust(wspace = .4)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "ax2 = sns.pointplot(x = beta_2, y = gamma_2)\n",
    "ax2.set_xticklabels(labels = beta_2, rotation = '80', fontdict = {'fontsize':12})\n",
    "ax2.set_xlabel('Name of Country', fontdict = {'fontsize':12})\n",
    "ax2.set_ylabel('Number of Successful Attacks', fontdict = {'fontsize':12})\n",
    "ax2.set_title('Countries with Most Activity and Number of Successful Attacks')\n",
    "plt.subplots_adjust(wspace = .3, hspace = .3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### E. Highly Targeted Areas:\n",
    "\n",
    "The next few graphs take a look at the target feature (i.e. the feature that describes what sector is targeted within the attacks) and how they are distributed according to other features.  After having run some preliminary feature selections, our algorithims highlighted the importance of the target features, so we wanted to take a look at it in more-depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Gathering the top-10 targets:\n",
    "big_targets = cyber_data['target_1txt'].value_counts().head(5)\n",
    "\n",
    "big_targets_mask = cyber_data['target_1txt'].apply(lambda x: x in big_targets)\n",
    "targeted_df = cyber_data[big_targets_mask]\n",
    "\n",
    "# Visualization Parameters:\n",
    "\n",
    "countplot_kwargs = {'edgecolor':'black',\n",
    "                    'linewidth':.85,\n",
    "                    'alpha':.85}\n",
    "countplot_rc = {'figure.dpi': 90,\n",
    "                'font.size': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.rc(countplot_rc)\n",
    "ax1 = sns.countplot(x = 'target_1txt', hue = 'region_txt', data = targeted_df, \n",
    "                    orient = 'h', palette = 'Paired', **countplot_kwargs)\n",
    "ax1.legend(loc = \"upper right\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Targeted Sectors\")\n",
    "plt.title(\"Geographical Location for Targeted Areas\")\n",
    "plt.xticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.rc(countplot_rc)\n",
    "ax2 = sns.countplot(x = 'target_1txt', hue = 'attack_1txt', data = targeted_df, orient = 'h',\n",
    "                    palette = 'Paired', **countplot_kwargs)\n",
    "ax2.legend(loc = 'upper right')\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Targeted Sectors\")\n",
    "plt.title(\"Targeted Areas and Attack Method\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 10))\n",
    "plt.rc(countplot_rc)\n",
    "ax3 = sns.countplot(x = 'target_1txt', hue = 'weapontxt', data = targeted_df, orient = 'h', \n",
    "                    palette = 'Paired', **countplot_kwargs)\n",
    "ax3.legend(loc = 'upper right')\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Targeted Sectors\")\n",
    "plt.title(\"Targeted Areas and Weapon Type\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del actives, actives_df, temp_output, beta_1, beta_2, gamma_1, gamma_2,\n",
    "del hot_countries, hot_countries_df, phi, temp_output2, mask3\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3. Feature Selection:\n",
    "\n",
    "Getting closer to modeling and using feature selection algorithms to see what will help us best minimize our feature set while maintaining the most amount of variation in our data.\n",
    "\n",
    "We mainly focused on Select KBest within sklearn and PCA analysis to give us two perspectives on the data (one that we can parse out as humans, namely Select KBest, and one that is mostly computationally described, namely PCA). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### A. Select K-Best:\n",
    "\n",
    "##### Assessing the Overall DataFrame and its Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Getting dummies on our training and test sets (slight wrangling involved):\n",
    "  # First dropping any na's:\n",
    "cyber_train_X.dropna(axis = 0, inplace = True)\n",
    "cyber_test_X.dropna(axis = 0, inplace = True)\n",
    "\n",
    "  # Then grabbing an index to make sure we maintain our train/test split:\n",
    "train_index = cyber_train_X.index\n",
    "test_index = cyber_test_X.index\n",
    "\n",
    "  # Dummy-time (we combined the dataframes here to make sure we didn't get duplicated dummies in both \n",
    "    # training and test sets):\n",
    "dummy_prep = pd.concat([cyber_train_X, cyber_test_X]).drop(['group_name', 'city', 'weapontxt'], axis = 1)\n",
    "dummy_1 = pd.get_dummies(dummy_prep)\n",
    "\n",
    "  # Re-filtering our Training/Test Inputs:\n",
    "cyber_train_dummy_X = dummy_1.loc[train_index]\n",
    "cyber_test_dummy_X = dummy_1.loc[test_index]\n",
    "\n",
    "  # Re-filtering our Training/Test Outputs:\n",
    "cyber_train_dummy_Y = cyber_train_Y.loc[train_index]\n",
    "cyber_test_dummy_Y = cyber_test_Y.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Making sure we have the same sizes still:\n",
    "print(cyber_train_dummy_X.shape)\n",
    "print(cyber_test_dummy_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting SelectKBest to our Features and output:\n",
    "  # Here we tried a number of sizes: 20, 30, 500 and 700. We found that 25-30 got us the best results.\n",
    "KBest_1 = feature_selection.SelectKBest(k = 25) \n",
    "cyber_train_KBest1 = KBest_1.fit_transform(cyber_train_dummy_X, cyber_train_dummy_Y)\n",
    "\n",
    "# Transforming the test-set\n",
    "cyber_test_KBest1 = KBest_1.transform(cyber_test_dummy_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a DF with the top 25 features:\n",
    "feature_mask = KBest_1.get_support(indices = True)\n",
    "KBest_1_features = pd.DataFrame(cyber_train_dummy_X.columns[feature_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "variables": {
     "KBest_1_features": {}
    }
   },
   "source": [
    "Here, we are getting a lot of return from the attack, target, sub-target and a few country features.  The doubt column indicates whether doubt exists regarding the classification of this incident as a terrorist incident, as opposed to some sort of other crime.  High-correlation here would make sense, but for now, we will focus on the columns below as the doubt feature is potentially over-correlated.\n",
    "\n",
    "{{KBest_1_features}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Assessing Individual Features:\n",
    "\n",
    "Running SelectKBest on a few features individually to see which of their values is selected as most important.  This will help us consolidate some of those values and make a more specific dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###### Group_name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Getting dummies on our training and test sets (slight wrangling involved):\n",
    "names_train_X = cyber_train_X['group_name']\n",
    "names_test_X = cyber_test_X['group_name']\n",
    "\n",
    "names_train_index = cyber_train_X['group_name'].index\n",
    "names_test_index = cyber_test_X['group_name'].index\n",
    "\n",
    "names_dummy_prep = pd.concat([names_train_X, names_test_X])\n",
    "names_dummy_1 = pd.get_dummies(names_dummy_prep)\n",
    "\n",
    "# Filtering Training/Test Inputs:\n",
    "names_train_dummy_X = names_dummy_1.loc[names_train_index]\n",
    "names_test_dummy_X = names_dummy_1.loc[names_test_index]\n",
    "\n",
    "# Filtering Training Outputs:\n",
    "names_train_dummy_Y = cyber_train_Y.loc[names_train_index]\n",
    "names_test_dummy_Y = cyber_test_Y.loc[names_test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting model to our features and output.\n",
    "  # Again, we tried 30, 50 and 150, here. It seemed like 25-30 features gave us the best results.\n",
    "KBest_names = feature_selection.SelectKBest(k = 10)  \n",
    "names_train_KBest = KBest_names.fit_transform(names_train_dummy_X, names_train_dummy_Y)\n",
    "\n",
    "# Transforming our test set.\n",
    "names_test_KBest = KBest_names.transform(names_test_dummy_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Summarizing the scores for those top 25 features in a df:\n",
    "\n",
    "names_mask = KBest_names.get_support(indices = True)\n",
    "KBest_names_features = pd.DataFrame(names_train_dummy_X.columns[names_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "variables": {
     "KBest_names_features": {}
    }
   },
   "source": [
    "It looks like some of our groupings from above made it into the top-25 features, which is reassuring that our efforts above produced a result.  This also gives us a slightly broader view of the terrorist groups that are highly active, as opposed to overly-specific groups that might wash out the activity in other countries.\n",
    "\n",
    "{{KBest_names_features}}\n",
    "\n",
    "This also points to another issue for consideration when performing future work on the dataset. When making these groups and filters, one will want to be sure to create groups that consider as much of the globe as possible. Otherwise, one would run the risk of coagulating a few groups together from one area, thereby increasing their significance, and over-powering the significance of other groups.  The groups we created above were an attempt at creating well-represented portions of the globe.  It would benefit, however, from more time and research so as to further tweak these groupings towards a higher accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###### City:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Getting dummies on our training and test sets (slight wrangling involved):\n",
    "city_train_X = cyber_train_X['city']\n",
    "city_test_X = cyber_test_X['city']\n",
    "\n",
    "city_train_index = cyber_train_X['city'].index\n",
    "city_test_index = cyber_test_X['city'].index\n",
    "\n",
    "city_dummy_prep = pd.concat([city_train_X, city_test_X])\n",
    "city_dummy_1 = pd.get_dummies(city_dummy_prep)\n",
    "\n",
    "# Training/Test Inputs:\n",
    "city_train_dummy_X = city_dummy_1.loc[city_train_index]\n",
    "city_test_dummy_X = city_dummy_1.loc[city_test_index]\n",
    "\n",
    "# Training Output:\n",
    "city_train_dummy_Y = cyber_train_Y.loc[city_train_index]\n",
    "city_test_dummy_Y = cyber_test_Y.loc[city_test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting model to our features and output.\n",
    "KBest_city = feature_selection.SelectKBest(k = 25) # Tried 30 and 150. 25-30 was our best range.\n",
    "city_train_KBest = KBest_city.fit_transform(city_train_dummy_X, city_train_dummy_Y)\n",
    "\n",
    "# Transforming our test set:\n",
    "city_test_KBest = KBest_city.transform(city_test_dummy_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Summarizing the scores for those top 25 features in a df:\n",
    "pd.set_option('max_rows', 101)\n",
    "city_mask = KBest_city.get_support(indices = True)\n",
    "KBest_city_features = pd.DataFrame(city_train_dummy_X.columns[city_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "variables": {
     "KBest_city_features": {}
    }
   },
   "source": [
    "{{KBest_city_features}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###### Specific_target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Getting dummies on our training and test sets (slight wrangling involved):\n",
    "spec_targ_train_X = cyber_train_X['specific_target']\n",
    "spec_targ_test_X = cyber_test_X['specific_target']\n",
    "\n",
    "spec_targ_train_index = cyber_train_X['specific_target'].index\n",
    "spec_targ_test_index = cyber_test_X['specific_target'].index\n",
    "\n",
    "spec_targ_dummy_prep = pd.concat([spec_targ_train_X, spec_targ_test_X])\n",
    "spec_targ_dummy_1 = pd.get_dummies(spec_targ_dummy_prep)\n",
    "\n",
    "# Training/Test Inputs:\n",
    "spec_targ_train_dummy_X = spec_targ_dummy_1.loc[spec_targ_train_index]\n",
    "spec_targ_test_dummy_X = spec_targ_dummy_1.loc[spec_targ_test_index]\n",
    "\n",
    "# Training Output:\n",
    "spec_targ_train_dummy_Y = cyber_train_Y.loc[spec_targ_train_index]\n",
    "spec_targ_test_dummy_Y = cyber_test_Y.loc[spec_targ_test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting the model to our features and training output:\n",
    "\n",
    "KBest_spec_targ = feature_selection.SelectKBest(k = 25) # Tried 5, but 3 was best.\n",
    "spec_targ_train_KBest = KBest_spec_targ.fit_transform(spec_targ_train_dummy_X, spec_targ_train_dummy_Y)\n",
    "\n",
    "# Transforming our test set:\n",
    "spec_targ_test_KBest = KBest_spec_targ.transform(spec_targ_test_dummy_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Summarizing the scores for those top 3 features in a df:\n",
    "\n",
    "spec_targ_mask = KBest_spec_targ.get_support(indices = True)\n",
    "KBest_spec_targ_features = pd.DataFrame(spec_targ_train_dummy_X.columns[spec_targ_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "variables": {
     "KBest_spec_targ_features": {}
    }
   },
   "source": [
    "From here, we can infer that while the data-set we are looking at somehow has consequences for cyber infrastructre or networks (including email and social networks as well as the physical networks), there seems to be a correlation with bombings and incendiary methods as well.  As such, we cannot rule out the possibility that cyber-related attacks are often related to physical or other forms of terrorist attacks (at least in the current analysis we are doing here).\n",
    "\n",
    "{{KBest_spec_targ_features}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### B. Principle Component Analysis:\n",
    "##### Assessing the Overall DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Using the whole dataset (cyber_train_data):\n",
    "PCA_1 = PCA(n_components = 25)  # Tried 30 and 500\n",
    "cyber_train_PCA = PCA_1.fit_transform(cyber_train_dummy_X)  \n",
    "cyber_test_PCA = PCA_1.transform(cyber_test_dummy_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "##### Assessing Individual Features\n",
    "\n",
    "###### Group_name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Now looking at group_name values:\n",
    "PCA_name = PCA(n_components = 25) # Tried 30 and 150\n",
    "name_train_PCA = PCA_name.fit_transform(names_train_dummy_X)\n",
    "name_test_PCA = PCA_name.transform(names_test_dummy_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "###### City:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Then some city stuff:\n",
    "PCA_cities = PCA(n_components = 25) # Tried 30 and 150\n",
    "cities_train_PCA = PCA_cities.fit_transform(city_train_dummy_X)\n",
    "cities_test_PCA = PCA_cities.transform(city_test_dummy_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "###### Specific_target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Specific_target:\n",
    "PCA_spec_targ = PCA(n_components = 3)  # Tried 5\n",
    "spec_targ_train_PCA = PCA_spec_targ.fit_transform(spec_targ_train_dummy_X)\n",
    "spec_targ_test_PCA = PCA_spec_targ.transform(spec_targ_test_dummy_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### C. Creating Specified DF with Selected Features:\n",
    "\n",
    "##### DataFrame from KBest Algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Training:\n",
    "alpha = pd.DataFrame(cyber_train_KBest1, columns = KBest_1_features[0])\n",
    "beta = pd.DataFrame(names_train_KBest, columns = KBest_names_features[0])\n",
    "gamma = pd.DataFrame(city_train_KBest, columns = KBest_city_features[0])\n",
    "delta = pd.DataFrame(spec_targ_train_KBest, columns = KBest_spec_targ_features[0])\n",
    "\n",
    "KBest_train_X = pd.concat([alpha, beta, gamma, delta], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Test:\n",
    "alpha2 = pd.DataFrame(cyber_test_KBest1, columns = KBest_1_features[0])\n",
    "beta2 = pd.DataFrame(names_test_KBest, columns = KBest_names_features[0])\n",
    "gamma2 = pd.DataFrame(city_test_KBest, columns = KBest_city_features[0])\n",
    "delta2 = pd.DataFrame(spec_targ_test_KBest, columns = KBest_spec_targ_features[0])\n",
    "\n",
    "KBest_test_X = pd.concat([alpha2, beta2, gamma2, delta2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del alpha, beta, gamma, delta, alpha2, beta2, gamma2, delta2, cyber_train_KBest1, names_train_KBest\n",
    "del city_train_KBest, spec_targ_train_KBest, cyber_test_KBest1, names_test_KBest, city_test_KBest\n",
    "del spec_targ_test_KBest\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### DataFrame from PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Training:\n",
    "cyber_train_PCA = pd.DataFrame(cyber_train_PCA)\n",
    "name_train_PCA = pd.DataFrame(name_train_PCA)\n",
    "cities_train_PCA = pd.DataFrame(cities_train_PCA)\n",
    "spec_targ_train_PCA = pd.DataFrame(spec_targ_train_PCA)\n",
    "\n",
    "PCA_train_X = pd.DataFrame()\n",
    "PCA_train_X = pd.concat([cyber_train_PCA, name_train_PCA, cities_train_PCA, spec_targ_train_PCA], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Test:\n",
    "cyber_test_PCA = pd.DataFrame(cyber_test_PCA)\n",
    "name_test_PCA = pd.DataFrame(name_test_PCA)\n",
    "cities_test_PCA = pd.DataFrame(cities_test_PCA)\n",
    "spec_targ_test_PCA = pd.DataFrame(spec_targ_test_PCA)\n",
    "\n",
    "PCA_test_X = pd.DataFrame()\n",
    "PCA_test_X = pd.concat([cyber_test_PCA, name_test_PCA, cities_test_PCA, spec_targ_test_PCA], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del cyber_train_PCA, name_train_PCA, cities_train_PCA, spec_targ_train_PCA, cyber_test_PCA\n",
    "del name_test_PCA, cities_test_PCA, spec_targ_test_PCA\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4. Preliminary Models:\n",
    "\n",
    "Starting with a simple Logistic Regression since our output feature is binary. Afterwards, we will move on to our Random Forest, Support Vector Classifier and Gradient Booster. We chose these models since they often work well with binary output features. These models will also be discussed below in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "prelim_results = pd.DataFrame(columns=['Test B.A. Score', 'FP', 'FN', 'Mean CV Score', 'CV Std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Logistic Regression:\n",
    "\n",
    "##### KBest Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "KBest_logistic = LogisticRegression()\n",
    "\n",
    "KBest_logistic = KBest_logistic.fit(KBest_train_X, cyber_train_dummy_Y)\n",
    "KBest_logistic_train_pred_ = KBest_logistic.predict(KBest_train_X)\n",
    "KBest_logistic_test_pred_ = KBest_logistic.predict(KBest_test_X)\n",
    "\n",
    "# Evaluation:\n",
    "  # Confustion Matrices:    \n",
    "KBest_logistic_confusion_train = confusion_matrix(cyber_train_dummy_Y, KBest_logistic_train_pred_, labels = [0, 1])\n",
    "KBest_logistic_confusion_test = confusion_matrix(cyber_test_dummy_Y, KBest_logistic_test_pred_, labels = [0, 1])\n",
    "\n",
    "  # Cross-validation and train/test scores:\n",
    "KBest_logistic_cv = cross_val_score(KBest_logistic, KBest_train_X, cyber_train_dummy_Y, \n",
    "                                    scoring = 'balanced_accuracy', cv = 5)\n",
    "\n",
    "  # Looking at balanced accuracy/f1 scores:\n",
    "KBest_logistic_train = balanced_accuracy_score(cyber_train_dummy_Y, KBest_logistic_train_pred_)    \n",
    "KBest_logistic_test = balanced_accuracy_score(cyber_test_dummy_Y, KBest_logistic_test_pred_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plusminus = u\"\\u00B1\"\n",
    "print(\"\\nThe mean cross-validation score is: {:.2%} {}{:.2%}\".format(KBest_logistic_cv.mean(),\n",
    "                                                                     plusminus, KBest_logistic_cv.std()))\n",
    "print(\"The cv scores are: {}\".format(KBest_logistic_cv))\n",
    "\n",
    "conf_df = pd.DataFrame(KBest_logistic_confusion_train)\n",
    "\n",
    "FP = conf_df.loc[0, 1]\n",
    "FN = conf_df.loc[1, 0]\n",
    "NegT = conf_df.iloc[0].sum()\n",
    "PosT = conf_df.iloc[1].sum()\n",
    "\n",
    "print(\"\\nTraining-Set Metrics:\")\n",
    "print(conf_df)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP, (FP / NegT)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN, (FN / PosT)))\n",
    "print('Balanced Accuracy: {:.2%}\\n'.format(KBest_logistic_train))\n",
    "\n",
    "conf_df2 = pd.DataFrame(KBest_logistic_confusion_test)\n",
    "\n",
    "FP2 = conf_df2.loc[0, 1]\n",
    "FN2 = conf_df2.loc[1, 0]\n",
    "NegT2 = conf_df2.iloc[0].sum()\n",
    "PosT2 = conf_df2.iloc[1].sum()\n",
    "\n",
    "print(\"Test-Set Metrics:\")\n",
    "print(conf_df2)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP2, (FP2 / NegT2)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN2, (FN2 / PosT2)))\n",
    "print('Balanced Accuracy: {:.2%}'.format(KBest_logistic_test))\n",
    "\n",
    "prelim_results = prelim_results.append({'Test B.A. Score': KBest_logistic_test, \n",
    "                                        'FP': FP2, \n",
    "                                        'FN': FN2, \n",
    "                                        'Mean CV Score': KBest_logistic_cv.mean(), \n",
    "                                        'CV Std': KBest_logistic_cv.std()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del KBest_logistic, KBest_logistic_train_pred_, KBest_logistic_test_pred_ , KBest_logistic_confusion_train\n",
    "del KBest_logistic_confusion_test, KBest_logistic_cv, KBest_logistic_train, KBest_logistic_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### PCA Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "PCA_logistic = LogisticRegression()\n",
    "\n",
    "PCA_logistic = PCA_logistic.fit(PCA_train_X, cyber_train_dummy_Y)\n",
    "PCA_logistic_train_pred_ = PCA_logistic.predict(PCA_train_X)\n",
    "PCA_logistic_test_pred_ = PCA_logistic.predict(PCA_test_X)\n",
    "\n",
    "# Evaluation:\n",
    "  # Confustion Matrices:    \n",
    "PCA_logistic_confusion_train = confusion_matrix(cyber_train_dummy_Y, PCA_logistic_train_pred_, labels = [0, 1])\n",
    "PCA_logistic_confusion_test = confusion_matrix(cyber_test_dummy_Y, PCA_logistic_test_pred_, labels = [0, 1])\n",
    "\n",
    "  # Cross-validation and train/test scores:\n",
    "PCA_logistic_cv = cross_val_score(PCA_logistic, PCA_train_X, cyber_train_dummy_Y,\n",
    "                                  scoring = 'balanced_accuracy', cv = 5)\n",
    "\n",
    "  # Looking at balanced accuracy/f1 scores:\n",
    "PCA_logistic_train = balanced_accuracy_score(cyber_train_dummy_Y, PCA_logistic_train_pred_)    \n",
    "PCA_logistic_test = balanced_accuracy_score(cyber_test_dummy_Y, PCA_logistic_test_pred_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nThe mean cross-validation score is: {:.2%} {}{:.2%}\".format(PCA_logistic_cv.mean(),\n",
    "                                                                     plusminus, PCA_logistic_cv.std()))\n",
    "print(\"The cv scores are: {}\".format(PCA_logistic_cv))\n",
    "\n",
    "conf_df = pd.DataFrame(PCA_logistic_confusion_train)\n",
    "\n",
    "FP = conf_df.loc[0, 1]\n",
    "FN = conf_df.loc[1, 0]\n",
    "NegT = conf_df.iloc[0].sum()\n",
    "PosT = conf_df.iloc[1].sum()\n",
    "\n",
    "print(\"\\nTraining-Set Metrics:\")\n",
    "print(conf_df)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP, (FP / NegT)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN, (FN / PosT)))\n",
    "print('Balanced Accuracy: {:.2%}\\n'.format(PCA_logistic_train))\n",
    "\n",
    "conf_df2 = pd.DataFrame(PCA_logistic_confusion_test)\n",
    "\n",
    "FP2 = conf_df2.loc[0, 1]\n",
    "FN2 = conf_df2.loc[1, 0]\n",
    "NegT2 = conf_df2.iloc[0].sum()\n",
    "PosT2 = conf_df2.iloc[1].sum()\n",
    "\n",
    "print(\"Test-Set Metrics:\")\n",
    "print(conf_df2)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP2, (FP2 / NegT2)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN2, (FN2 / PosT2)))\n",
    "print('Balanced Accuracy: {:.2%}'.format(PCA_logistic_test))\n",
    "\n",
    "prelim_results = prelim_results.append({'Test B.A. Score': PCA_logistic_test, \n",
    "                                        'FP': FP2, \n",
    "                                        'FN': FN2, \n",
    "                                        'Mean CV Score': PCA_logistic_cv.mean(), \n",
    "                                        'CV Std': PCA_logistic_cv.std()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now, while we do have some decent scores here, especially regarding the true positive predictions, we do have a class imbalance issue we will need to take into consideration (as demonstrated below).  One way of doing that will work on increasing the accuracy of our true negatives and focusing less on our true positives. It will also help to take into consideration our False Negatives and Positives. Lowering these will help strengthen our model and give us more predictive integrity.  In other words, we want to make sure we avoid as many False Negatives (i.e. instances where our model does not predict a terrorist attack, when instead one does, in fact, occur) as possible.  We also want to be sure we are keeping our False Positive count as low as possible since responding to predicted terrorist incidents when there are none will exhaust resources and employees - in turn taking away their energies from realistic threats. \n",
    "\n",
    "In order to do so, we have implemented the Balanced Accuracy score, which gives us an average of our False Negatives and Positives.  It allows us to consider another aspect of the model results outside of the training and test-set scores (which only allow us to see on aspect of a model's predictive results).  The Balanced Accuracy is a nice addition to the confusion matrix, which gives us the hard-numbers which are factored into the Balanced Accuracy score.  In assessing the models above along with those below, we will be looking at all of these evaluation methods in order to determine which model is the best and make our reasoning as well-rounded as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print(cyber_train_dummy_Y.success.value_counts())\n",
    "print(cyber_test_dummy_Y.success.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del PCA_logistic, PCA_logistic_train_pred_, PCA_logistic_test_pred_ , PCA_logistic_confusion_train\n",
    "del PCA_logistic_confusion_test, PCA_logistic_cv, PCA_logistic_train, PCA_logistic_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Random Forest:\n",
    "\n",
    "##### KBest Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "KBest_forest = RandomForestClassifier(n_estimators = 30, max_depth = 12)\n",
    "\n",
    "KBest_forest = KBest_forest.fit(KBest_train_X, cyber_train_dummy_Y)\n",
    "KBest_forest_train_pred_ = KBest_forest.predict(KBest_train_X)\n",
    "KBest_forest_test_pred_ = KBest_forest.predict(KBest_test_X)\n",
    "\n",
    "# Evaluation:\n",
    "  # Confustion Matrices:    \n",
    "KBest_forest_confusion_train = confusion_matrix(cyber_train_dummy_Y, KBest_forest_train_pred_, labels = [0, 1])\n",
    "KBest_forest_confusion_test = confusion_matrix(cyber_test_dummy_Y, KBest_forest_test_pred_, labels = [0, 1])\n",
    "\n",
    "  # Cross-validation and train/test scores:\n",
    "KBest_forest_cv = cross_val_score(KBest_forest, KBest_train_X, cyber_train_dummy_Y, \n",
    "                                  scoring = 'balanced_accuracy', cv = 5)\n",
    "\n",
    "  # Looking at balanced accuracy/f1 scores:\n",
    "KBest_forest_train = balanced_accuracy_score(cyber_train_dummy_Y, KBest_forest_train_pred_)    \n",
    "KBest_forest_test = balanced_accuracy_score(cyber_test_dummy_Y, KBest_forest_test_pred_)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nThe mean cross-validation score is: {:.2%} {}{:.2%}\".format(KBest_forest_cv.mean(),\n",
    "                                                                     plusminus, KBest_forest_cv.std()))\n",
    "print(\"The cv scores are: {}\".format(KBest_forest_cv))\n",
    "\n",
    "conf_df = pd.DataFrame(KBest_forest_confusion_train)\n",
    "\n",
    "FP = conf_df.loc[0, 1]\n",
    "FN = conf_df.loc[1, 0]\n",
    "NegT = conf_df.iloc[0].sum()\n",
    "PosT = conf_df.iloc[1].sum()\n",
    "\n",
    "print(\"\\nTraining-Set Metrics:\")\n",
    "print(conf_df)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP, (FP / NegT)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN, (FN / PosT)))\n",
    "print('Balanced Accuracy: {:.2%}\\n'.format(KBest_forest_train))\n",
    "\n",
    "conf_df2 = pd.DataFrame(KBest_forest_confusion_test)\n",
    "\n",
    "FP2 = conf_df2.loc[0, 1]\n",
    "FN2 = conf_df2.loc[1, 0]\n",
    "NegT2 = conf_df2.iloc[0].sum()\n",
    "PosT2 = conf_df2.iloc[1].sum()\n",
    "\n",
    "print(\"Test-Set Metrics:\")\n",
    "print(conf_df2)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP2, (FP2 / NegT2)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN2, (FN2 / PosT2)))\n",
    "print('Balanced Accuracy: {:.2%}'.format(KBest_forest_test))\n",
    "\n",
    "print('\\n\\nFeature Importances:\\n')\n",
    "feat_imp = pd.DataFrame(KBest_forest.feature_importances_.round(2), index = KBest_train_X.columns, \n",
    "                        columns = [\"Importances\"])\n",
    "display(feat_imp.sort_values('Importances', ascending = False))\n",
    "\n",
    "prelim_results = prelim_results.append({'Test B.A. Score': KBest_forest_test, \n",
    "                                        'FP': FP2, \n",
    "                                        'FN': FN2, \n",
    "                                        'Mean CV Score': KBest_forest_cv.mean(), \n",
    "                                        'CV Std': KBest_forest_cv.std()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### PCA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "PCA_forest = RandomForestClassifier()\n",
    "\n",
    "PCA_forest = PCA_forest.fit(PCA_train_X, cyber_train_dummy_Y)\n",
    "PCA_forest_train_pred_ = PCA_forest.predict(PCA_train_X)\n",
    "PCA_forest_test_pred_ = PCA_forest.predict(PCA_test_X)\n",
    "\n",
    "# Evaluation:\n",
    "  # Confusion Matrices:\n",
    "PCA_forest_confusion_train = confusion_matrix(cyber_train_dummy_Y, PCA_forest_train_pred_, labels = [0, 1])\n",
    "PCA_forest_confusion_test = confusion_matrix(cyber_test_dummy_Y, PCA_forest_test_pred_, labels = [0, 1])\n",
    "\n",
    "  # Cross-validation and train/test scores:\n",
    "PCA_forest_cv = cross_val_score(PCA_forest, PCA_train_X, cyber_train_dummy_Y, \n",
    "                                scoring = 'balanced_accuracy', cv = 5)\n",
    "\n",
    "  # Looking and balanced accuracy/f1 scores:\n",
    "PCA_forest_train = balanced_accuracy_score(cyber_train_dummy_Y, PCA_forest_train_pred_)    \n",
    "PCA_forest_test = balanced_accuracy_score(cyber_test_dummy_Y, PCA_forest_test_pred_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nThe mean cross-validation score is: {:.2%} {}{:.2%}\".format(PCA_forest_cv.mean(),\n",
    "                                                                     plusminus, PCA_forest_cv.std()))\n",
    "print(\"The cv scores are: {}\".format(PCA_forest_cv))\n",
    "\n",
    "conf_df = pd.DataFrame(PCA_forest_confusion_train)\n",
    "\n",
    "FP = conf_df.loc[0, 1]\n",
    "FN = conf_df.loc[1, 0]\n",
    "NegT = conf_df.iloc[0].sum()\n",
    "PosT = conf_df.iloc[1].sum()\n",
    "\n",
    "print(\"\\nTraining-Set Metrics:\")\n",
    "print(conf_df)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP, (FP / NegT)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN, (FN / PosT)))\n",
    "print('Balanced Accuracy: {:.2%}\\n'.format(PCA_forest_train))\n",
    "\n",
    "conf_df2 = pd.DataFrame(PCA_forest_confusion_test)\n",
    "\n",
    "FP2 = conf_df2.loc[0, 1]\n",
    "FN2 = conf_df2.loc[1, 0]\n",
    "NegT2 = conf_df2.iloc[0].sum()\n",
    "PosT2 = conf_df2.iloc[1].sum()\n",
    "\n",
    "print(\"Test-Set Metrics:\")\n",
    "print(conf_df2)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP2, (FP2 / NegT2)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN2, (FN2 / PosT2)))\n",
    "print('Balanced Accuracy: {:.2%}'.format(PCA_forest_test))\n",
    "\n",
    "prelim_results = prelim_results.append({'Test B.A. Score': PCA_forest_test, \n",
    "                                        'FP': FP2, \n",
    "                                        'FN': FN2, \n",
    "                                        'Mean CV Score': PCA_forest_cv.mean(), \n",
    "                                        'CV Std': PCA_forest_cv.std()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here, we can see quite a bit of over-fitting given that the training score and balanced accuracy scores are nearly perfect, while the test score is about 5 percentage points lower than the training score and over 20 points below the balanced accuracy (a drastic difference compared to what we have seen thus far). The nice aspect about the Random Forest, however, is that it lets us look into the feature importances which were used in creating the model, which we saw in the KBest model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del PCA_forest, PCA_forest_train_pred_, PCA_forest_test_pred_ , PCA_forest_confusion_train, \n",
    "del PCA_forest_confusion_test, PCA_forest_cv, PCA_forest_train, PCA_forest_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Support Vector Classifier:\n",
    "\n",
    "##### KBest Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "KBest_SVC = SVC()\n",
    "\n",
    "KBest_SVC = KBest_SVC.fit(KBest_train_X, cyber_train_dummy_Y)\n",
    "KBest_SVC_train_pred_ = KBest_SVC.predict(KBest_train_X)\n",
    "KBest_SVC_test_pred_ = KBest_SVC.predict(KBest_test_X)\n",
    "\n",
    "# Evaluation:\n",
    "  # Confusion matrices:\n",
    "KBest_SVC_confusion_train = confusion_matrix(cyber_train_dummy_Y, KBest_SVC_train_pred_, labels = [0, 1])\n",
    "KBest_SVC_confusion_test = confusion_matrix(cyber_test_dummy_Y, KBest_SVC_test_pred_, labels = [0, 1])\n",
    "\n",
    "  # Cross-validation and train/test scores:\n",
    "KBest_SVC_cv = cross_val_score(KBest_SVC, KBest_train_X, cyber_train_dummy_Y, \n",
    "                               scoring = 'balanced_accuracy', cv = 5)\n",
    "\n",
    "  # Looking at balanced accuracy/f1 scores:\n",
    "KBest_SVC_train = balanced_accuracy_score(cyber_train_dummy_Y, KBest_SVC_train_pred_)\n",
    "KBest_SVC_test = balanced_accuracy_score(cyber_test_dummy_Y, KBest_SVC_test_pred_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nThe mean cross-validation score is: {:.2%} {}{:.2%}\".format(KBest_SVC_cv.mean(),\n",
    "                                                                     plusminus, KBest_SVC_cv.std()))\n",
    "print(\"The cv scores are: {}\".format(KBest_SVC_cv))\n",
    "\n",
    "conf_df = pd.DataFrame(KBest_SVC_confusion_train)\n",
    "\n",
    "FP = conf_df.loc[0, 1]\n",
    "FN = conf_df.loc[1, 0]\n",
    "NegT = conf_df.iloc[0].sum()\n",
    "PosT = conf_df.iloc[1].sum()\n",
    "\n",
    "print(\"\\nTraining-Set Metrics:\")\n",
    "print(conf_df)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP, (FP / NegT)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN, (FN / PosT)))\n",
    "print('Balanced Accuracy: {:.2%}\\n'.format(KBest_SVC_train))\n",
    "\n",
    "conf_df2 = pd.DataFrame(KBest_SVC_confusion_test)\n",
    "\n",
    "FP2 = conf_df2.loc[0, 1]\n",
    "FN2 = conf_df2.loc[1, 0]\n",
    "NegT2 = conf_df2.iloc[0].sum()\n",
    "PosT2 = conf_df2.iloc[1].sum()\n",
    "\n",
    "print(\"Test-Set Metrics:\")\n",
    "print(conf_df2)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP2, (FP2 / NegT2)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN2, (FN2 / PosT2)))\n",
    "print('Balanced Accuracy: {:.2%}'.format(KBest_SVC_test))\n",
    "\n",
    "prelim_results = prelim_results.append({'Test B.A. Score': KBest_SVC_test, \n",
    "                                        'FP': FP2, \n",
    "                                        'FN': FN2, \n",
    "                                        'Mean CV Score': KBest_SVC_cv.mean(), \n",
    "                                        'CV Std': KBest_SVC_cv.std()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del KBest_SVC, KBest_SVC_train_pred_, KBest_SVC_test_pred_ , KBest_SVC_confusion_train\n",
    "del KBest_SVC_confusion_test, KBest_SVC_cv, KBest_SVC_train, KBest_SVC_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### PCA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "PCA_SVC = SVC()\n",
    "\n",
    "PCA_SVC = PCA_SVC.fit(PCA_train_X, cyber_train_dummy_Y)\n",
    "PCA_SVC_train_pred_ = PCA_SVC.predict(PCA_train_X)\n",
    "PCA_SVC_test_pred_ = PCA_SVC.predict(PCA_test_X)\n",
    "\n",
    "# Evaluation:\n",
    "  # Confusion Matrices:\n",
    "PCA_SVC_confusion_train = confusion_matrix(cyber_train_dummy_Y, PCA_SVC_train_pred_, labels = [0, 1])\n",
    "PCA_SVC_confusion_test = confusion_matrix(cyber_test_dummy_Y, PCA_SVC_test_pred_, labels = [0, 1])\n",
    "\n",
    "  # Cross-validation and train/test scores:\n",
    "PCA_SVC_cv = cross_val_score(PCA_SVC, PCA_train_X, cyber_train_dummy_Y, \n",
    "                             scoring = 'balanced_accuracy', cv = 5)\n",
    "\n",
    "  # Looking at the F1/balanced accuracy scores:\n",
    "PCA_SVC_train = balanced_accuracy_score(cyber_train_dummy_Y, PCA_SVC_train_pred_)\n",
    "PCA_SVC_test = balanced_accuracy_score(cyber_test_dummy_Y, PCA_SVC_test_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nThe mean cross-validation score is: {:.2%} {}{:.2%}\".format(PCA_SVC_cv.mean(),\n",
    "                                                                     plusminus, PCA_SVC_cv.std()))\n",
    "print(\"The cv scores are: {}\".format(PCA_SVC_cv))\n",
    "\n",
    "conf_df = pd.DataFrame(PCA_SVC_confusion_train)\n",
    "\n",
    "FP = conf_df.loc[0, 1]\n",
    "FN = conf_df.loc[1, 0]\n",
    "NegT = conf_df.iloc[0].sum()\n",
    "PosT = conf_df.iloc[1].sum()\n",
    "\n",
    "print(\"\\nTraining-Set Metrics:\")\n",
    "print(conf_df)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP, (FP / NegT)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN, (FN / PosT)))\n",
    "print('Balanced Accuracy: {:.2%}\\n'.format(PCA_SVC_train))\n",
    "\n",
    "conf_df2 = pd.DataFrame(PCA_SVC_confusion_test)\n",
    "\n",
    "FP2 = conf_df2.loc[0, 1]\n",
    "FN2 = conf_df2.loc[1, 0]\n",
    "NegT2 = conf_df2.iloc[0].sum()\n",
    "PosT2 = conf_df2.iloc[1].sum()\n",
    "\n",
    "print(\"Test-Set Metrics:\")\n",
    "print(conf_df2)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP2, (FP2 / NegT2)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN2, (FN2 / PosT2)))\n",
    "print('Balanced Accuracy: {:.2%}'.format(PCA_SVC_test))\n",
    "\n",
    "prelim_results = prelim_results.append({'Test B.A. Score': PCA_SVC_test, \n",
    "                                        'FP': FP2, \n",
    "                                        'FN': FN2, \n",
    "                                        'Mean CV Score': PCA_SVC_cv.mean(), \n",
    "                                        'CV Std': PCA_SVC_cv.std()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These support vector models are considerably stable in the sense that they are able to achieve similar test scores throughout various rounds, which is good.  The balanced accuracy scores are decent and the amount of error is considerably less than the models above. Let's take a look at one more round of model-type before we make this our official model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del PCA_SVC, PCA_SVC_train_pred_, PCA_SVC_test_pred_ , PCA_SVC_confusion_train\n",
    "del PCA_SVC_confusion_test, PCA_SVC_cv, PCA_SVC_train, PCA_SVC_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Gradient Boosting:\n",
    "\n",
    "##### KBest Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "KBest_GBC = GradientBoostingClassifier()\n",
    "\n",
    "KBest_GBC = KBest_GBC.fit(KBest_train_X, cyber_train_dummy_Y)\n",
    "KBest_GBC_train_pred_ = KBest_GBC.predict(KBest_train_X)\n",
    "KBest_GBC_test_pred_ = KBest_GBC.predict(KBest_test_X)\n",
    "\n",
    "# Evaluation:\n",
    "  # Confusion matrices:    \n",
    "KBest_GBC_confusion_train = confusion_matrix(cyber_train_dummy_Y, KBest_GBC_train_pred_, labels = [0, 1])\n",
    "KBest_GBC_confusion_test = confusion_matrix(cyber_test_dummy_Y, KBest_GBC_test_pred_, labels = [0, 1])\n",
    "\n",
    "  # Cross-validation and train/test scores:\n",
    "KBest_GBC_cv = cross_val_score(KBest_GBC, KBest_train_X, cyber_train_dummy_Y, \n",
    "                               scoring = 'balanced_accuracy', cv = 5)\n",
    "\n",
    "\n",
    "  # Looking at the F1/balanced-accuracy scores:\n",
    "KBest_GBC_train = balanced_accuracy_score(cyber_train_dummy_Y, KBest_GBC_train_pred_)\n",
    "KBest_GBC_test = balanced_accuracy_score(cyber_test_dummy_Y, KBest_GBC_test_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nThe mean cross-validation score is: {:.2%} {}{:.2%}\".format(KBest_GBC_cv.mean(),\n",
    "                                                                     plusminus, KBest_GBC_cv.std()))\n",
    "print(\"The cv scores are: {}\".format(KBest_GBC_cv))\n",
    "\n",
    "conf_df = pd.DataFrame(KBest_GBC_confusion_train)\n",
    "\n",
    "FP = conf_df.loc[0, 1]\n",
    "FN = conf_df.loc[1, 0]\n",
    "NegT = conf_df.iloc[0].sum()\n",
    "PosT = conf_df.iloc[1].sum()\n",
    "\n",
    "print(\"\\nTraining-Set Metrics:\")\n",
    "print(conf_df)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP, (FP / NegT)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN, (FN / PosT)))\n",
    "print('Balanced Accuracy: {:.2%}\\n'.format(KBest_GBC_train))\n",
    "\n",
    "conf_df2 = pd.DataFrame(KBest_GBC_confusion_test)\n",
    "\n",
    "FP2 = conf_df2.loc[0, 1]\n",
    "FN2 = conf_df2.loc[1, 0]\n",
    "NegT2 = conf_df2.iloc[0].sum()\n",
    "PosT2 = conf_df2.iloc[1].sum()\n",
    "\n",
    "print(\"Test-Set Metrics:\")\n",
    "print(conf_df2)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP2, (FP2 / NegT2)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN2, (FN2 / PosT2)))\n",
    "print('Balanced Accuracy: {:.2%}'.format(KBest_GBC_test))\n",
    "\n",
    "print('\\n\\nFeature Importances:\\n')\n",
    "feat_imp = pd.DataFrame(KBest_GBC.feature_importances_.round(2), index = KBest_train_X.columns, \n",
    "                        columns = [\"Importances\"])\n",
    "display(feat_imp.sort_values('Importances', ascending = False))\n",
    "\n",
    "prelim_results = prelim_results.append({'Test B.A. Score': KBest_GBC_test, \n",
    "                                        'FP': FP2, \n",
    "                                        'FN': FN2, \n",
    "                                        'Mean CV Score': KBest_GBC_cv.mean(), \n",
    "                                        'CV Std': KBest_GBC_cv.std()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del KBest_GBC, KBest_GBC_train_pred_, KBest_GBC_test_pred_ , KBest_GBC_confusion_train\n",
    "del KBest_GBC_confusion_test, KBest_GBC_cv, KBest_GBC_train, KBest_GBC_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### PCA Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "PCA_GBC = GradientBoostingClassifier()\n",
    "\n",
    "PCA_GBC = PCA_GBC.fit(PCA_train_X, cyber_train_dummy_Y)\n",
    "PCA_GBC_train_pred_ = PCA_GBC.predict(PCA_train_X) \n",
    "PCA_GBC_test_pred_ = PCA_GBC.predict(PCA_test_X) \n",
    "\n",
    "# Evaluation:\n",
    "\n",
    "  # Confusion matrices:\n",
    "PCA_GBC_confusion_train = confusion_matrix(cyber_train_dummy_Y, PCA_GBC_train_pred_, labels = [0, 1])\n",
    "PCA_GBC_confusion_test = confusion_matrix(cyber_test_dummy_Y, PCA_GBC_test_pred_, labels = [0, 1])\n",
    "\n",
    "  # Cross_validation and train/test score:\n",
    "PCA_GBC_cv = cross_val_score(PCA_GBC, PCA_train_X, cyber_train_dummy_Y, \n",
    "                             scoring = 'balanced_accuracy', cv = 5)\n",
    "\n",
    "  # Looking at the F1/balanced accuracy scores:\n",
    "PCA_GBC_train = balanced_accuracy_score(cyber_train_dummy_Y, PCA_GBC_train_pred_)\n",
    "PCA_GBC_test = balanced_accuracy_score(cyber_test_dummy_Y, PCA_GBC_test_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plusminus = u\"\\u00B1\"\n",
    "print(\"\\nThe mean cross-validation score is: {:.2%} {}{:.2%}\".format(PCA_GBC_cv.mean(),\n",
    "                                                                     plusminus, PCA_GBC_cv.std()))\n",
    "print(\"The cv scores are: {}\".format(PCA_GBC_cv))\n",
    "\n",
    "conf_df = pd.DataFrame(PCA_GBC_confusion_train)\n",
    "\n",
    "FP = conf_df.loc[0, 1]\n",
    "FN = conf_df.loc[1, 0]\n",
    "NegT = conf_df.iloc[0].sum()\n",
    "PosT = conf_df.iloc[1].sum()\n",
    "\n",
    "print(\"\\nTraining-Set Metrics:\")\n",
    "print(conf_df)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP, (FP / NegT)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN, (FN / PosT)))\n",
    "print('Balanced Accuracy: {:.2%}\\n'.format(PCA_GBC_train))\n",
    "\n",
    "conf_df2 = pd.DataFrame(PCA_GBC_confusion_test)\n",
    "\n",
    "FP2 = conf_df2.loc[0, 1]\n",
    "FN2 = conf_df2.loc[1, 0]\n",
    "NegT2 = conf_df2.iloc[0].sum()\n",
    "PosT2 = conf_df2.iloc[1].sum()\n",
    "\n",
    "print(\"Test-Set Metrics:\")\n",
    "print(conf_df2)\n",
    "print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP2, (FP2 / NegT2)))\n",
    "print('False Negative/Type II Error: {} ({:.2%})'.format(FN2, (FN2 / PosT2)))\n",
    "print('Balanced Accuracy: {:.2%}'.format(PCA_GBC_test))\n",
    "\n",
    "prelim_results = prelim_results.append({'Test B.A. Score': PCA_GBC_test, \n",
    "                                        'FP': FP2, \n",
    "                                        'FN': FN2, \n",
    "                                        'Mean CV Score': PCA_GBC_cv.mean(), \n",
    "                                        'CV Std': PCA_GBC_cv.std()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del PCA_GBC, PCA_GBC_train_pred_, PCA_GBC_test_pred_ , PCA_GBC_confusion_train\n",
    "del PCA_GBC_confusion_test, PCA_GBC_cv, PCA_GBC_train, PCA_GBC_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "variables": {
     "prelim_results": {}
    }
   },
   "source": [
    "#### Summary of First Models:\n",
    "\n",
    "> Based on these preliminary results, we were able to get relatively similar results from nearly all models, but it looks like our Random Forest Classifier did best (with the Support Vector Classifier coming in at a close second). In addition, the Random Forest model did best with the KBest feature-set. We will try and focus on the Random Forest model with our next phase and tune the parameters to see if we can optimize those results.  \n",
    "\n",
    "> Results Table:\n",
    "\n",
    "{{prelim_results}}\n",
    "\n",
    "> Now onto tuning our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del PCA_spec_targ, PCA_name, PCA_cities, PCA_1, KBest_spec_targ, KBest_names, conf_df, conf_df2\n",
    "del KBest_city, KBest_1, city_mask, feature_mask, names_mask, spec_targ_mask, feature_selection\n",
    "del KBest_spec_targ_features, KBest_city_features, KBest_names_features, KBest_1_features\n",
    "del spec_targ_test_index, city_test_dummy_Y, names_test_dummy_Y, spec_targ_test_dummy_Y, spec_targ_test_dummy_X\n",
    "del X_test_start_index, city_test_index, names_test_index, spec_targ_train_index, city_train_dummy_Y\n",
    "del names_train_dummy_Y, spec_targ_train_dummy_Y, spec_targ_train_dummy_X, city_train_index, names_train_index\n",
    "del names_test_dummy_X, names_train_X, city_train_X, spec_targ_train_X, names_test_X, city_test_X, spec_targ_test_X\n",
    "del PosT2, PosT, names_train_dummy_X, city_test_dummy_X, city_train_dummy_X\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "\n",
    "cleaner = sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5. Improving our Scores:\n",
    "\n",
    "#### A. Investigating the Data Itself:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def RF_KBest_Eval():   \n",
    "    print(\"\\nThe mean cross-validation score is: {:.2%} {}{:.2%}\".format(KBest_forest_cv.mean(),\n",
    "                                                                         plusminus, KBest_forest_cv.std()))\n",
    "    print(\"The cv scores are: {}\".format(KBest_forest_cv))\n",
    "\n",
    "    conf_df = pd.DataFrame(KBest_forest_confusion_train)\n",
    "\n",
    "    FP = conf_df.loc[0, 1]\n",
    "    FN = conf_df.loc[1, 0]\n",
    "    NegT = conf_df.iloc[0].sum()\n",
    "    PosT = conf_df.iloc[1].sum()\n",
    "\n",
    "    print(\"\\nTraining-Set Metrics:\")\n",
    "    print(conf_df)\n",
    "    print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP, (FP / NegT)))\n",
    "    print('False Negative/Type II Error: {} ({:.2%})'.format(FN, (FN / PosT)))\n",
    "    print('Balanced Accuracy: {:.2%}\\n'.format(KBest_forest_train))\n",
    "\n",
    "    conf_df2 = pd.DataFrame(KBest_forest_confusion_test)\n",
    "\n",
    "    FP2 = conf_df2.loc[0, 1]\n",
    "    FN2 = conf_df2.loc[1, 0]\n",
    "    NegT2 = conf_df2.iloc[0].sum()\n",
    "    PosT2 = conf_df2.iloc[1].sum()\n",
    "\n",
    "    print(\"Test-Set Metrics:\")\n",
    "    print(conf_df2)\n",
    "    print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP2, (FP2 / NegT2)))\n",
    "    print('False Negative/Type II Error: {} ({:.2%})'.format(FN2, (FN2 / PosT2)))\n",
    "    print('Balanced Accuracy: {:.2%}'.format(KBest_forest_test))\n",
    "\n",
    "    print('\\n\\nFeature Importances:\\n')\n",
    "    feat_imp = pd.DataFrame(KBest_forest.feature_importances_.round(2), index = KBest_train_X.columns, \n",
    "                            columns = [\"Importances\"])\n",
    "    display(feat_imp.sort_values('Importances', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "RF_KBest_Eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# our comm-related df:\n",
    "comms = cyber_data.loc[cyber_data['specific_target'] == 'Comm-Related']\n",
    "\n",
    "# Isolating Assassination instances (in our visualization dataframe so we can look at hour our outcome variable\n",
    "# correlates with them):\n",
    "attacks_as = cyber_train_X.loc[cyber_train_X['attack_1txt'] == 'Assassination']\n",
    "\n",
    "# From here, we can start our funneling technique (since there are a lot of unknowns):\n",
    "  # General description:\n",
    "attacks_as_descr = attacks_as.describe(include = 'all')\n",
    "attacks_doubt = pd.DataFrame(attacks_as.doubt.value_counts())\n",
    "attacks_grp_attrib = pd.DataFrame(attacks_as.group_attrib_crtainty.value_counts())\n",
    "attacks_individual = pd.DataFrame(attacks_as.unaffil_individ.value_counts())\n",
    "\n",
    "  # Retrieving our 'success' columns for comparison:\n",
    "success_mask = cyber_train_Y.index.map(lambda x: x in attacks_as.index)\n",
    "s_col = cyber_train_Y[success_mask]\n",
    "attacks_as['success'] = s_col['success']\n",
    "attacks_success = pd.DataFrame(attacks_as.success.value_counts())\n",
    " \n",
    " # Locating the successful instances:\n",
    "attacks_viz_success = attacks_as.loc[attacks_as['success'] == 1]   \n",
    "\n",
    "  # Locating the unknown group_names:\n",
    "unknown_success = attacks_viz_success.loc[attacks_viz_success['group_name'] == 'Unknown']\n",
    "\n",
    "  # Looking at the specific counts here:\n",
    "unaffiliated_individual = pd.DataFrame(unknown_success.unaffil_individ.value_counts())\n",
    "suspicious_attribution = pd.DataFrame(unknown_success.group_attrib_crtainty.value_counts())\n",
    "locations = pd.DataFrame(unknown_success.country_txt.value_counts())\n",
    "regions = pd.DataFrame(unknown_success.region_txt.value_counts())\n",
    "cities = pd.DataFrame(unknown_success.city.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "variables": {
     "attacks_doubt": {},
     "attacks_grp_attrib": {},
     "attacks_individual": {},
     "attacks_success": {}
    }
   },
   "source": [
    "Now that we've seen what our preliminary model gave as our most important feature, we have a difficult challenge on our hands, given that most of our most-frequent values in a handful of features are 'Unknown.'  How does one predict given that our most-common evidence falls into an 'Unknown' category? Let's look at our class balances first:\n",
    "\n",
    "<head>\n",
    "    <table>\n",
    "        <th style = 'text-align:center'> Is there doubt regarding it's classification as an instance of terrorism? </th>\n",
    "        <th style = 'text-align:center'> Was the attempt successful?</th>\n",
    "        <th style = 'text-align:center'> Is there uncertainty regarding the attribution of the attack to the perpetrating group? </th>\n",
    "        <th style = 'text-align:center'> Was it an unaffiliated individual? </th>\n",
    "        <tr>\n",
    "            <td> {{attacks_doubt}} </td>\n",
    "            <td> {{attacks_success}} </td>\n",
    "            <td> {{attacks_grp_attrib}} </td>\n",
    "            <td> {{attacks_individual}} </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</head>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "variables": {
     "attacks_success": {},
     "success_class_balance": {}
    }
   },
   "source": [
    "After looking at this, we then look at the data we have funnelled down a bit (i.e. data which fits the following criteria):\n",
    "* The attack-type is an assassination.\n",
    "* The attack was successful.\n",
    "* The group-name is unknown.\n",
    "\n",
    "> We also know that our feature selection and preliminary models were effectie above since we seem to have found a feature/set of features, where our class imbalance has been reduced significantly.  Let's take a look at our beginning class imbalance in comparison.  Here, we can see that we went from a 90% imbalance to a 50% imbalance and a distribution where our unsuccessful attacks represent one-sixth of their entire class.\n",
    "\n",
    "<head>\n",
    "    <table>\n",
    "        <th> original-data: </th>\n",
    "        <th> funnelled-data: </th>\n",
    "        <tr>\n",
    "            <td> {{success_class_balance}} </td>\n",
    "            <td> {{attacks_success}} </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</head>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "variables": {
     "cities.head(10)": {},
     "locations.head(10)": {},
     "regions.head(10)": {},
     "suspicious_attribution": {},
     "unaffiliated_individual": {}
    }
   },
   "source": [
    "Here are the value-counts for some of the features (within our funnelled data-set) that would be feasible for someone in government or intelligence to work with:\n",
    "\n",
    "<head>\n",
    "    <table>\n",
    "        <th style = 'text-align:center'> Perpetrator unaffiliated? </th>\n",
    "        <th style = 'text-align:center'> Suspicious group attribution? </th>\n",
    "        <tr>\n",
    "            <td style = 'vertical-align:top'> {{unaffiliated_individual}} </td>\n",
    "            <td style = 'vertical-align:top'> {{suspicious_attribution}} </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</head>\n",
    "\n",
    "<head>\n",
    "    <table>\n",
    "        <th style = 'text-align:center'> Location: Top 10 Countries </th>\n",
    "        <th style = 'text-align:center'> Location: Top 10 Regions </th>\n",
    "        <th style = 'text-align:center'> Location: Top 10 Cities </th>\n",
    "        <tr>\n",
    "            <td style = 'vertical-align:top'> {{locations.head(10)}} </td>\n",
    "            <td style = 'vertical-align:top'> {{regions.head(10)}} </td>\n",
    "            <td style = 'vertical-align:top'> {{cities.head(10)}} </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</head>\n",
    "       \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As such, we can see that these datapoints have the following characteristics:\n",
    "* Nearly always conducted by an individual affiliated with a group.\n",
    "* The group is, more-frequently than not, attributed as the culprit with certainty.\n",
    "* The locations are frequently in the Middle East, Asia and North Africa.\n",
    "\n",
    "While we could engineer a feature that classifies observations as either having these characteristics or not, it would only really be useful in describing this dataset.  In the wild, it would not be too helpful for anyone trying to prevent or respond to these attacks.  As such, the most effective method for engineering a barometer for the above analysis, would be looking at the 361 group-names and creating a column that indicates their presence or not.  This will give anyone working in the industry a list of specific groups to focus on as well.  Let's go ahead and get those group-names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Getting our group-names:\n",
    "act_successful_groups = attacks_viz_success.loc[attacks_viz_success['group_attrib_crtainty'] == 0]\n",
    "\n",
    "  # Saving the top-10 to a variable:\n",
    "red_list = pd.DataFrame(act_successful_groups.group_name.value_counts().head(11).drop('Unknown', axis = 0))\n",
    "\n",
    "  # Getting overall attack attempts by groupname (while maintaining train/test split after all the grouping\n",
    "    # above):\n",
    "ungrouped_data = cyber_data.index.map(lambda x: x in cyber_train_X.index)\n",
    "ungrouped_training_data = cyber_data[ungrouped_data]\n",
    "\n",
    "training_red_listers = ungrouped_training_data.group_name.map(lambda x: x in red_list.index)\n",
    "training_redlist_attack_totals = ungrouped_training_data[training_red_listers].group_name.value_counts()\n",
    "training_red_list = ungrouped_training_data[training_red_listers]\n",
    "  \n",
    "  # from the totals above:\n",
    "red_list['total_attacks'] = [311, 109, 767, 261, 64, 261, 77, 159, 19, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Then we apply the engineering to our main training data-frame: \n",
    "cyber_train_X.loc[cyber_train_X['group_name'] == red_list.index[0], 'Barometer'] = (red_list.group_name[0] / red_list.total_attacks[0])*100\n",
    "cyber_train_X.loc[cyber_train_X['group_name'] == red_list.index[1], 'Barometer'] = (red_list.group_name[1] / red_list.total_attacks[1])*100\n",
    "cyber_train_X.loc[cyber_train_X['group_name'] == red_list.index[2], 'Barometer'] = (red_list.group_name[2] / red_list.total_attacks[2])*100\n",
    "cyber_train_X.loc[cyber_train_X['group_name'] == red_list.index[3], 'Barometer'] = (red_list.group_name[3] / red_list.total_attacks[3])*100\n",
    "cyber_train_X.loc[cyber_train_X['group_name'] == red_list.index[4], 'Barometer'] = (red_list.group_name[4] / red_list.total_attacks[4])*100\n",
    "cyber_train_X.loc[cyber_train_X['group_name'] == red_list.index[5], 'Barometer'] = (red_list.group_name[5] / red_list.total_attacks[5])*100\n",
    "cyber_train_X.loc[cyber_train_X['group_name'] == red_list.index[6], 'Barometer'] = (red_list.group_name[6] / red_list.total_attacks[6])*100\n",
    "cyber_train_X.loc[cyber_train_X['group_name'] == red_list.index[7], 'Barometer'] = (red_list.group_name[7] / red_list.total_attacks[7])*100\n",
    "cyber_train_X.loc[cyber_train_X['group_name'] == red_list.index[8], 'Barometer'] = (red_list.group_name[8] / red_list.total_attacks[8])*100\n",
    "cyber_train_X.loc[cyber_train_X['group_name'] == red_list.index[9], 'Barometer'] = (red_list.group_name[9] / red_list.total_attacks[9])*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Then to our test set:\n",
    "cyber_test_X.loc[cyber_test_X['group_name'] == red_list.index[0], 'Barometer'] = (red_list.group_name[0] / red_list.total_attacks[0])*100\n",
    "cyber_test_X.loc[cyber_test_X['group_name'] == red_list.index[1], 'Barometer'] = (red_list.group_name[1] / red_list.total_attacks[1])*100\n",
    "cyber_test_X.loc[cyber_test_X['group_name'] == red_list.index[2], 'Barometer'] = (red_list.group_name[2] / red_list.total_attacks[2])*100\n",
    "cyber_test_X.loc[cyber_test_X['group_name'] == red_list.index[3], 'Barometer'] = (red_list.group_name[3] / red_list.total_attacks[3])*100\n",
    "cyber_test_X.loc[cyber_test_X['group_name'] == red_list.index[4], 'Barometer'] = (red_list.group_name[4] / red_list.total_attacks[4])*100\n",
    "cyber_test_X.loc[cyber_test_X['group_name'] == red_list.index[5], 'Barometer'] = (red_list.group_name[5] / red_list.total_attacks[5])*100\n",
    "cyber_test_X.loc[cyber_test_X['group_name'] == red_list.index[6], 'Barometer'] = (red_list.group_name[6] / red_list.total_attacks[6])*100\n",
    "cyber_test_X.loc[cyber_test_X['group_name'] == red_list.index[7], 'Barometer'] = (red_list.group_name[7] / red_list.total_attacks[7])*100\n",
    "cyber_test_X.loc[cyber_test_X['group_name'] == red_list.index[8], 'Barometer'] = (red_list.group_name[8] / red_list.total_attacks[8])*100\n",
    "cyber_test_X.loc[cyber_test_X['group_name'] == red_list.index[9], 'Barometer'] = (red_list.group_name[9] / red_list.total_attacks[9])*100\n",
    "\n",
    "# Replacing the nan's in that specific column\n",
    "cyber_train_X['Barometer'] = cyber_train_X['Barometer'].replace(np.nan, 0)\n",
    "cyber_test_X['Barometer'] = cyber_test_X['Barometer'].replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "KBest_train_X2 = pd.DataFrame(KBest_train_X)\n",
    "KBest_test_X2 = pd.DataFrame(KBest_test_X)\n",
    "\n",
    "KBest_train_X2['Barometer'] = cyber_train_X['Barometer'].values\n",
    "KBest_test_X2['Barometer'] = cyber_test_X['Barometer'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 6. Tuning our Final Model:\n",
    "\n",
    "Here, we will try and use a for loop to run through a set of parameters, which we will then use to visualize the parameters which will optimize our model's predictive power.  For the moment, the parameters we will focus on are the 'n_estimators' and 'max_depth.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Double checking the shape of our engineered feature-set:\n",
    "KBest_train_X2.shape\n",
    "KBest_test_X2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "KBest_Grid = RandomForestClassifier(criterion = 'entropy')\n",
    "\n",
    "params = [{'n_estimators': np.arange(40, 420, 20), \n",
    "           'max_depth': np.arange(3, 16, 1)}]\n",
    "\n",
    "params_2 = [{'n_estimators': np.arange(420, 20, -20), \n",
    "             'max_depth': np.arange(15, 2, -1)}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Random Forest with Original Data-Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_grid = GridSearchCV(KBest_Grid, params, cv = 5, scoring = 'balanced_accuracy')\n",
    "forest_grid.fit(KBest_train_X, cyber_train_dummy_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "\n",
    "cleaner = sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "del dummy_1, spec_targ_dummy_1, spec_targ_train_dummy_X, city_dummy_1, city_train_dummy_X\n",
    "del cyber_test_dummy_X, targeted_df, spec_targ_test_dummy_X, ungrouped_training_data, city_test_dummy_X\n",
    "del dummy_prep, names_dummy_1, PCA_train_X, names_train_dummy_X, names_dummy_prep, PCA_test_X\n",
    "del names_test_dummy_X, spec_targ_dummy_prep, spec_targ_train_X, attacks_viz_success, comms, names_test_X\n",
    "del attacks_as, city_dummy_prep, names_train_X, training_red_list, act_successful_groups, city_train_X\n",
    "del ungrouped_data, success_mask, unknown_success, spec_targ_test_X, city_train_index, names_train_index\n",
    "del city_test_X, KBest_forest_train_pred_, KBest_logistic_train_pred_, spec_targ_train_index, train_index, \n",
    "del big_targets_mask, names_train_dummy_Y, spec_targ_train_dummy_Y, X_train_start_index, city_test_dummy_Y\n",
    "del city_train_dummy_Y, s_col, cities, feat_imp, city_test_index, test_index, names_test_index\n",
    "del training_red_listers, KBest_RF_train_pred_, cyber_test_dummy_Y, names_test_dummy_Y, spec_targ_test_dummy_Y\n",
    "del KBest_RF_test_pred_, KBest_forest_test_pred_, KBest_logistic_test_pred_, spec_targ_test_index\n",
    "del attacks_as_descr, cyber_data_objects, locations, KBest_spec_targ_features, KBest_1_features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_grid_2 = GridSearchCV(KBest_Grid, params_2, cv = 5, scoring = 'balanced_accuracy')\n",
    "forest_grid_2.fit(KBest_train_X, cyber_train_dummy_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Random Forest with New Feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_grid_3 = GridSearchCV(KBest_Grid, params, cv = 5, scoring = 'balanced_accuracy')\n",
    "forest_grid_3.fit(KBest_train_X2, cyber_train_dummy_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_grid_4 = GridSearchCV(KBest_Grid, params_2, cv = 5, scoring = 'balanced_accuracy')\n",
    "forest_grid_4.fit(KBest_train_X2, cyber_train_dummy_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forest_grid.best_params_)\n",
    "print(forest_grid_2.best_params_)\n",
    "print(forest_grid_3.best_params_)\n",
    "print(forest_grid_4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forest_grid.best_score_)\n",
    "print(forest_grid_2.best_score_)\n",
    "print(forest_grid_3.best_score_)\n",
    "print(forest_grid_4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Custom GridSearch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 1. RandomForest with KBest (original features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "param_dict = {'n_estimators': [600, 600, 600, 600, 600, 600], \n",
    "              'max_depth' : [11, 12, 13, 14, 15, 16]}\n",
    "\n",
    "param_df = pd.DataFrame(param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "results_list = pd.DataFrame(columns=['B.A. Score', 'FP', 'FN', 'Mean CV Score', 'CV Std'])\n",
    "plusminus = u\"\\u00B1\"\n",
    "\n",
    "for row in param_df.itertuples(index = False):\n",
    "\n",
    "    KBest_RF = RandomForestClassifier(n_estimators = row[0], max_depth = row[1])\n",
    "\n",
    "    KBest_RF = KBest_RF.fit(KBest_train_X, cyber_train_dummy_Y)\n",
    "    KBest_RF_train_pred_ = KBest_RF.predict(KBest_train_X) \n",
    "    KBest_RF_test_pred_ = KBest_RF.predict(KBest_test_X) \n",
    "\n",
    "    # Evaluation:\n",
    "\n",
    "      # Confusion matrices:\n",
    "    KBest_RF_confusion_train = confusion_matrix(cyber_train_dummy_Y, KBest_RF_train_pred_, labels = [0, 1])\n",
    "    KBest_RF_confusion_test = confusion_matrix(cyber_test_dummy_Y, KBest_RF_test_pred_, labels = [0, 1])\n",
    "\n",
    "      # Cross_validation and train/test score:\n",
    "    KBest_RF_cv = cross_val_score(KBest_RF, KBest_train_X, cyber_train_dummy_Y, cv = 5, \n",
    "                                  scoring = 'balanced_accuracy')\n",
    "\n",
    "      # Looking at the F1/balanced accuracy scores:\n",
    "    KBest_RF_train = balanced_accuracy_score(cyber_train_dummy_Y, KBest_RF_train_pred_)\n",
    "    KBest_RF_test = balanced_accuracy_score(cyber_test_dummy_Y, KBest_RF_test_pred_)\n",
    "    \n",
    "      # Getting some scores on cross-validation, False Negatives and Positives and Balanced Accuracy:\n",
    "    print(\"\\nThe mean cross-validation score is: {:.2%} {}{:.2%}\".format(KBest_RF_cv.mean(),\n",
    "                                                                     plusminus, KBest_RF_cv.std()))\n",
    "    conf_df = pd.DataFrame(KBest_RF_confusion_train)\n",
    "  \n",
    "    FP = conf_df.loc[0, 1]\n",
    "    FN = conf_df.loc[1, 0]\n",
    "    NegT = conf_df.iloc[0].sum()\n",
    "    PosT = conf_df.iloc[1].sum()\n",
    "    \n",
    "    print(\"Training set results:\")\n",
    "    print(conf_df)\n",
    "    print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP, (FP / NegT)))\n",
    "    print('False Negative/Type II Error: {} ({:.2%})'.format(FN, (FN / PosT)))\n",
    "    print('Balanced Accuracy: {:.2%}\\n'.format(KBest_RF_train))\n",
    "    \n",
    "    conf_df2 = pd.DataFrame(KBest_RF_confusion_test)\n",
    "\n",
    "    FP2 = conf_df2.loc[0, 1]\n",
    "    FN2 = conf_df2.loc[1, 0]\n",
    "    NegT2 = conf_df2.iloc[0].sum()\n",
    "    PosT2 = conf_df2.iloc[1].sum()\n",
    "    \n",
    "    print(\"Test set results:\")\n",
    "    print(conf_df2)\n",
    "    print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP2, (FP2 / NegT2)))\n",
    "    print('False Negative/Type II Error: {} ({:.2%})'.format(FN2, (FN2 / PosT2)))\n",
    "    print('Balanced Accuracy: {:.2%}'.format(KBest_RF_test))\n",
    "    print('-----------------')\n",
    "    \n",
    "    results_list = results_list.append({'B.A. Score': KBest_RF_test, \n",
    "                                        'FP': FP2,\n",
    "                                        'FN': FN2,\n",
    "                                        'Mean CV Score': KBest_RF_cv.mean(), \n",
    "                                        'CV Std': KBest_RF_cv.std()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "variables": {
     "results_list": {}
    }
   },
   "source": [
    "Here are the results we received for Random Forest Model (with tweaked parameters and our original data-set):\n",
    "    \n",
    "  {{results_list}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### 2. RandomForest with KBest (engineered feature added):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "results_list_2 = pd.DataFrame(columns=['B.A. Score', 'FP', 'FN', 'Mean CV Score', 'CV Std'])\n",
    "plusminus = u\"\\u00B1\"\n",
    "\n",
    "for row in param_df.itertuples(index = False):\n",
    "\n",
    "    KBest_RF = RandomForestClassifier(n_estimators = row[0], max_depth = row[1])\n",
    "\n",
    "    KBest_RF = KBest_RF.fit(KBest_train_X2, cyber_train_dummy_Y)\n",
    "    KBest_RF_train_pred_ = KBest_RF.predict(KBest_train_X2) \n",
    "    KBest_RF_test_pred_ = KBest_RF.predict(KBest_test_X2) \n",
    "\n",
    "    # Evaluation:\n",
    "\n",
    "      # Confusion matrices:\n",
    "    KBest_RF_confusion_train = confusion_matrix(cyber_train_dummy_Y, KBest_RF_train_pred_, labels = [0, 1])\n",
    "    KBest_RF_confusion_test = confusion_matrix(cyber_test_dummy_Y, KBest_RF_test_pred_, labels = [0, 1])\n",
    "\n",
    "      # Cross_validation and train/test score:\n",
    "    KBest_RF_cv = cross_val_score(KBest_RF, KBest_train_X2, cyber_train_dummy_Y, cv = 5, \n",
    "                                  scoring = 'balanced_accuracy')\n",
    "\n",
    "      # Looking at the F1/balanced accuracy scores:\n",
    "    KBest_RF_train = balanced_accuracy_score(cyber_train_dummy_Y, KBest_RF_train_pred_)\n",
    "    KBest_RF_test = balanced_accuracy_score(cyber_test_dummy_Y, KBest_RF_test_pred_)\n",
    "    \n",
    "      # Getting some scores on cross-validation, False Negatives and Positives and Balanced Accuracy:\n",
    "    print(\"\\nThe mean cross-validation score is: {:.2%} {}{:.2%}\".format(KBest_RF_cv.mean(),\n",
    "                                                                     plusminus, KBest_RF_cv.std()))\n",
    "    conf_df = pd.DataFrame(KBest_RF_confusion_train)\n",
    "  \n",
    "    FP = conf_df.loc[0, 1]\n",
    "    FN = conf_df.loc[1, 0]\n",
    "    NegT = conf_df.iloc[0].sum()\n",
    "    PosT = conf_df.iloc[1].sum()\n",
    "    \n",
    "    print(\"Training set results:\")\n",
    "    print(conf_df)\n",
    "    print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP, (FP / NegT)))\n",
    "    print('False Negative/Type II Error: {} ({:.2%})'.format(FN, (FN / PosT)))\n",
    "    print('Balanced Accuracy: {:.2%}\\n'.format(KBest_RF_train))\n",
    "    \n",
    "    conf_df2 = pd.DataFrame(KBest_RF_confusion_test)\n",
    "\n",
    "    FP2 = conf_df2.loc[0, 1]\n",
    "    FN2 = conf_df2.loc[1, 0]\n",
    "    NegT2 = conf_df2.iloc[0].sum()\n",
    "    PosT2 = conf_df2.iloc[1].sum()\n",
    "    \n",
    "    print(\"Test set results:\")\n",
    "    print(conf_df2)\n",
    "    print('\\nFalse Positive/Type I Error: {} ({:.2%})'.format(FP2, (FP2 / NegT2)))\n",
    "    print('False Negative/Type II Error: {} ({:.2%})'.format(FN2, (FN2 / PosT2)))\n",
    "    print('Balanced Accuracy: {:.2%}'.format(KBest_RF_test))\n",
    "    print('-----------------')\n",
    "    \n",
    "    results_list_2 = results_list_2.append({'B.A. Score': KBest_RF_test, \n",
    "                                            'FP': FP2,\n",
    "                                            'FN': FN2,\n",
    "                                            'Mean CV Score': KBest_RF_cv.mean(), \n",
    "                                            'CV Std': KBest_RF_cv.std()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "variables": {
     "results_list_2": {}
    }
   },
   "source": [
    "Here are the results we received for Random Forest Model (with tweaked parameters and our engineered feature):\n",
    "    \n",
    "  {{results_list_2}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 7. Final Analysis, Considerations and Avenues for Further Research:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Potential Weaknesses:\n",
    "\n",
    "While we were able to get some decent scores, there are a few things to not regarding this model and its dataset.  First of all, the filters would greatly benefit from further research and detailed attention.  The above filters are merely a start and represent a base amount of research.  It could certainly serve as a starting point for someone with expertise in the field.\n",
    "\n",
    "In addition, the filters we applied could be susceptible to a certain amount of bias: the filter itself will not be able to catch all instances of cyber-related terrorism conclusively; more likely than not it will miss one certain aspect or another. Increasing the number of eyes on the model and data will help with this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Further research:\n",
    "\n",
    "Given the richness of the variables within this dataset, there are plenty of avenues for further research.  One could use Regex to search the summary and motive columns for further detail and insight into the nature of these cyber-related tasks.  The filter above is relatively broad and potentially encapsulates instances that many might not consider related to 'cyber' events.  It would be interesting to create a more intricate regex filter which could give us a more detailed understanding of the 'cyber' aspect of these events: How specifically are they related and in what manners? What geographical locations tend to be hotbeds for such activity.  What targets are specified and why?  The 'motive' feature, in particular, could have extensive benefits with prediction, depending on the vocabulary used by those conducting the study and entering the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Explanatory v. Predictive Power:\n",
    "\n",
    "With the current analysis, our goal lies mainly in the predictive power of our model - in other words, its ability to fit with the current data and produce an output with completely new data - preferably an output with as little variation in this new accuracy score as possible. We are trying to look at the trends in our current data and use it to identify the classifications and probabilities in which new or future observations will fall.  An explanatory model, with regards to a dataset describing Terrorism, might have interest to a scholar or an academic institution in the sense that it reveals behaviors and patterns of observations that have already occurred, but it has no bearing on future observations. It would offer no suggestions on what these patterns might say regarding incoming data (and in this case, future terror attacks). \n",
    "\n",
    "The caveat, however, is making sure that our model adapts well to new input (or test) data so that the variation between training and test results can be as minimal as possible (i.e. so the difference between the model's prediction and reality is minimal).  Predictive analysis, especially in a terror-related context, involves considerably more risk than an explanatory model, and should be handled with an intense attention to detail and accuracy.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "General References:\n",
    "\n",
    "Referenced the following sites for honing my knowledge of the models, python, etc:\n",
    "\n",
    "1. https://www.analyticsvidhya.com/blog/2017/06/a-comprehensive-guide-for-linear-ridge-and-lasso-regression/\n",
    "2. https://machinelearningmastery.com/feature-selection-machine-learning-python/\n",
    "3. https://medium.com/@pushkarmandot/what-is-the-significance-of-c-value-in-support-vector-machine-28224e852c5a\n",
    "4. A big shout out to Mike Swirsky for pointing out this link to me (submitted by the user 'Abdou' on Stack Overflow: https://stackoverflow.com/questions/40993626/list-memory-usage-in-ipython-and-jupyter)"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/0bdf5140cd2a27ed2b47eafe4d20273a"
  },
  "celltoolbar": "Slideshow",
  "gist": {
   "data": {
    "description": "CyberTerrorism6.ipynb",
    "public": true
   },
   "id": "0bdf5140cd2a27ed2b47eafe4d20273a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "510px",
    "width": "555px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 444,
   "position": {
    "height": "40px",
    "left": "1306px",
    "right": "20px",
    "top": "120px",
    "width": "356px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
