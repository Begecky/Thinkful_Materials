{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import operator as op\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing, Cleaning and Selecting Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Epicurious.csv')\n",
    "data2 = data.drop(['calories', 'protein', 'fat', 'sodium'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With Nutrtional Info:\n",
    "\n",
    "rating_corr = data.corr().rating\n",
    "rating_corr = rating_corr.sort_values(ascending = False)\n",
    "\n",
    "key_list = list(rating_corr[0:50].keys())\n",
    "data = pd.DataFrame(data[key_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without Nutrtional Info:\n",
    "\n",
    "rating_corr2 = data2.corr().rating\n",
    "rating_corr2 = rating_corr2.sort_values(ascending = False)\n",
    "\n",
    "key_list2 = list(rating_corr2[0:31].keys())\n",
    "data2 = pd.DataFrame(data2[key_list2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Classification Party:\n",
    "data.loc[data['rating'] >= 4, 'binary_rating'] = 1\n",
    "data.loc[data['rating'] < 4, 'binary_rating'] = 0\n",
    "\n",
    "data2.loc[data2['rating'] >= 4, 'binary_rating'] = 1\n",
    "data2.loc[data2['rating'] < 4, 'binary_rating'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting our Training and Test Sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X1 = data2.drop(['rating', 'binary_rating'], 1)\n",
    "y1 = data2.binary_rating\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_1 = SVC(kernel = 'linear')\n",
    "svc_1.fit(X1_train, y1_train)\n",
    "\n",
    "y1_pred_ = svc_1.predict(X1_test)\n",
    "\n",
    "svc_1_cfmat = confusion_matrix(y1_test, y1_pred_, labels = [0, 1])\n",
    "svc_1_cvscores = cross_val_score(svc_1, X1, y1, cv = 10)\n",
    "svc_1_trainscore = svc_1.score(X1_train, y1_train)\n",
    "svc_1_testscore = svc_1.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients are: \n",
      " [[ 1.99860836e+00  8.59749428e-04  2.05594448e-04 -3.20998315e-04\n",
      "   1.58906287e-04  1.02660349e-03  9.66509176e-05 -1.07255392e-04\n",
      "   5.16524306e-04 -5.87026161e-04 -2.20392046e-04  5.77719992e-04\n",
      "   5.21931170e-04  3.39467966e-04  1.05890835e-03 -9.67217955e-05\n",
      "   1.99758571e+00 -4.42523820e-04  3.04112173e-04 -2.86772277e-04\n",
      "  -1.16023226e-04  6.66492278e-04  6.09964607e-04  2.02119523e-04\n",
      "   7.06738111e-04  4.46270631e-04  6.64260310e-04 -1.81036898e-04\n",
      "   5.75005480e-04  1.29589169e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The coefficients are: \\n {}\".format(svc_1.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV Scores are: \n",
      " [0.55284148 0.55383848 0.55732802 0.56530409 0.54912718 0.55062344\n",
      " 0.57406484 0.53516209 0.55239521 0.55339321]\n"
     ]
    }
   ],
   "source": [
    "print(\"The CV Scores are: \\n {}\".format(svc_1_cvscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean and STD of the CV Scores are:\n",
      " Mean:0.5544078043071993. STD: 0.009664971552262066.\n",
      "The Training score is: 0.5536437877937784\n",
      "The Test score is: 0.5574669658439292\n",
      "[[ 454 1401]\n",
      " [ 374 1782]]\n",
      "Specificity:[[0.82653061]]\n",
      "Sensitivity:[[0.24474394]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The Mean and STD of the CV Scores are:\\n Mean:{}. STD: {}.\".format(svc_1_cvscores.mean(), \n",
    "                                                                          svc_1_cvscores.std()))\n",
    "print(\"The Training score is: {}\".format(svc_1_trainscore))\n",
    "print(\"The Test score is: {}\".format(svc_1_testscore))\n",
    "print(svc_1_cfmat)\n",
    "print(\"Specificity:{}\".format(svc_1_cfmat[1:2, 1:2]/(svc_1_cfmat[1:2, 0:1] + svc_1_cfmat[1:2, 1:2])))\n",
    "print(\"Sensitivity:{}\".format(svc_1_cfmat[0:1, 0:1]/(svc_1_cfmat[0:1, 0:1] + svc_1_cfmat[0:1, 1:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts for Data2: 4.375    8019\n",
      "3.750    5169\n",
      "5.000    2719\n",
      "0.000    1836\n",
      "3.125    1489\n",
      "2.500     532\n",
      "1.250     164\n",
      "1.875     124\n",
      "Name: rating, dtype: int64\n",
      "Value Counts for our Binary Column: \n",
      " 1.0    10738\n",
      "0.0     9314\n",
      "Name: binary_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Value Counts for Data2: {}\".format(data2.rating.value_counts()))\n",
    "print(\"Value Counts for our Binary Column: \\n {}\".format(data2.binary_rating.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = data.drop(['rating', 'binary_rating'], 1)\n",
    "y2 = data.binary_rating\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_2 = SVC(kernel = 'linear')\n",
    "svc_2.fit(X2_train, y2_train)\n",
    "\n",
    "y2_pred_ = svc_2.predict(X2_test)\n",
    "\n",
    "svc_2_cfmat = confusion_matrix(y2_test, y2_pred_, labels = [0, 1])\n",
    "svc_2_cvscores = cross_val_score(svc_2, X2, y2, cv = 10)\n",
    "svc_2_trainscore = svc_2.score(X2_train, y2_train)\n",
    "svc_2_testscore = svc_2.score(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients are: \n",
      " [[ 1.24847418  0.15716924  0.24507018 -0.04072991  0.15790374  0.43825547\n",
      "   0.07248807 -0.02526013  0.23835764 -0.07920606 -0.07817526  0.28581627\n",
      "   0.34238851  0.20884113  0.43808281  0.08278367  0.76124946 -0.2090276\n",
      "   0.20526987 -0.12059186  0.04838711  0.09694742  0.24045194  0.11577093\n",
      "   0.39982624  0.19171237  0.39590641 -0.08369852  0.47475643  0.11344484\n",
      "   0.6539698   0.28893508  0.04175122  0.21631996  0.3363189   0.19718094\n",
      "   0.33130265  0.31289277  0.33595707  0.06784213 -0.36401064  0.33032709\n",
      "   0.34855891  0.23676866  0.31151587  0.09601881  0.36725806  0.17222813\n",
      "  -0.0092481 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The coefficients are: \\n {}\".format(svc_2.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV Scores are: \n",
      " [0.56779661 0.5667996  0.55633101 0.58624128 0.56608479 0.57605985\n",
      " 0.59351621 0.5446384  0.57235529 0.55289421]\n"
     ]
    }
   ],
   "source": [
    "print(\"The CV Scores are: \\n {}\".format(svc_2_cvscores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mean and STD of the CV Scores are:\n",
      " Mean:0.5682717247384779. STD: 0.014079336862241885.\n",
      "The Training score is: 0.5760239386571909\n",
      "The Test score is: 0.5676888556469708\n",
      "[[ 773 1073]\n",
      " [ 661 1504]]\n",
      "Specificity:[[0.69468822]]\n",
      "Sensitivity:[[0.41874323]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The Mean and STD of the CV Scores are:\\n Mean:{}. STD: {}.\".format(svc_2_cvscores.mean(), \n",
    "                                                                          svc_2_cvscores.std()))\n",
    "print(\"The Training score is: {}\".format(svc_2_trainscore))\n",
    "print(\"The Test score is: {}\".format(svc_2_testscore))\n",
    "print(svc_2_cfmat)\n",
    "print(\"Specificity:{}\".format(svc_2_cfmat[1:2, 1:2]/(svc_2_cfmat[1:2, 0:1] + svc_2_cfmat[1:2, 1:2])))\n",
    "print(\"Sensitivity:{}\".format(svc_2_cfmat[0:1, 0:1]/(svc_2_cfmat[0:1, 0:1] + svc_2_cfmat[0:1, 1:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Counts for Data: 4.375    8019\n",
      "3.750    5169\n",
      "5.000    2719\n",
      "0.000    1836\n",
      "3.125    1489\n",
      "2.500     532\n",
      "1.250     164\n",
      "1.875     124\n",
      "Name: rating, dtype: int64\n",
      "Value Counts for our Binary Column: \n",
      " 1.0    10738\n",
      "0.0     9314\n",
      "Name: binary_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Value Counts for Data: {}\".format(data.rating.value_counts()))\n",
    "print(\"Value Counts for our Binary Column: \\n {}\".format(data.binary_rating.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Based on these correlation maps, you can see that there is definitely a bias here: people who have choosen these recipes are more than likely to give them a rating of four or five. People tend not to choose recipes that they believe they will not like.  Given that they have most-likely choosen a recipe which seemed good in the first place, there is a distinct head-start towards a positive rating.  This would explain why the single elements of food are not necessarily the greatest indicator of a positive rating, but the fact that the recipe was selected in the first place is significantly more indicative.\n",
    "\n",
    "> A way to avoid such a bias would be to distribute the recipes, and especially the foods, to people who haven't necessarily choosen them on the internet. That way, people would be rating a recipe that they had not choosen themselves, but one place in front of them (relatively) randomly. \n",
    "\n",
    "> Given that our binary classes are diveded fairly evenly, we don't have to worry about class imbalance here - our main concern is the lack of correlation amongst the features and the outcome variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
